{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Open Source LLM using the Azure ML Python SDK (MLflow)\n",
    "\n",
    "### Overview\n",
    "\n",
    "Azure ML Workspace is compatible with MLflow and can be used as an MLflow Tracking Server, as described in the following official guide from Microsoft. MLflow provides features such as experiment tracking, model management, and model deployment, allowing you to manage data science and machine learning workflows more efficiently and systematically. Below are the main advantages of using Azure ML and MLflow together.\n",
    "\n",
    "#### 1. Experiment tracking and management\n",
    "\n",
    "You can systematically manage the parameters, metrics, and artifacts of all your experiments. Integrating with Azur eML allows you to easily track and manage this information within your Azure ML workspace.\n",
    "\n",
    "#### 2. Model management\n",
    "\n",
    "MLflow provides a model registry for model versioning. Integrate with AzureML to systematically manage and deploy all versions of your models. When combined with AzureML's deployment capabilities, models can be easily deployed to a variety of environments (e.g. Azure Kubernetes Service, Azure Container Instances).\n",
    "\n",
    "#### 3. Reproducibility and collaboration\n",
    "\n",
    "MLflow records the parameters and environment of every experiment, so you can accurately reproduce the experiment. This is very useful when you need to redo the same experiment across collaborating team members, or when you need to rerun an experiment at a later date.\n",
    "\n",
    "#### 4. CI/CD integration\n",
    "\n",
    "MLflow makes it easy to implement continuous integration (CI) and continuous deployment (CD) of machine learning models. Integrate with Azure DevOps or GitHub Actions to automatically run training, validation, and deployment processes as model changes occur.\n",
    "\n",
    "#### 5. Integrating Logging with HF\n",
    "\n",
    "When training a model with Hugging Face's Trainer API, if you specify `report_to=\"azure_ml\"`, basic indicators will be automatically logged without any additional code. Of course, you can freely log custom indicators using Bring Your Own Script like the conventional method, but Azure ML's basic logging function is also excellent, so try using it as a baseline.\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "---\n",
    "\n",
    "### Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Kernel: python31014jvsc74a57bd01f90a0206bde5cf3732dab79adbbcc7570d5fab64b89fc69d46a8fe33664a709\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "lab_prep_dir = os.getcwd().split(\"SLMWorkshopCN\")[0] + \"SLMWorkshopCN/0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(lab_prep_dir))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 16:02:24,152 - logger - INFO - ===== 0. Azure ML Training Info =====\n",
      "2025-02-26 16:02:24,153 - logger - INFO - AZURE_SUBSCRIPTION_ID=49aee8bf-3f02-464f-a0ba-e3467e7d85e2\n",
      "2025-02-26 16:02:24,154 - logger - INFO - AZURE_RESOURCE_GROUP=rg-slmwrkshp_9\n",
      "2025-02-26 16:02:24,155 - logger - INFO - AZURE_WORKSPACE=mlw-pgwgybluulpec\n",
      "2025-02-26 16:02:24,156 - logger - INFO - AZURE_DATA_NAME=lgds-gsm8k-main-demo\n",
      "2025-02-26 16:02:24,157 - logger - INFO - DATA_DIR=./dataset\n",
      "2025-02-26 16:02:24,158 - logger - INFO - CLOUD_DIR=./cloud\n",
      "2025-02-26 16:02:24,159 - logger - INFO - HF_MODEL_NAME_OR_PATH=microsoft/phi-4\n",
      "2025-02-26 16:02:24,160 - logger - INFO - azure_env_name=llm-sft-2024-11-05\n",
      "2025-02-26 16:02:24,161 - logger - INFO - azure_compute_cluster_name=gpu-h100\n",
      "2025-02-26 16:02:24,162 - logger - INFO - azure_compute_cluster_size=Standard_NC40ads_H100_v5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "import yaml\n",
    "from logger import logger\n",
    "from datetime import datetime\n",
    "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open('config_prd.yml') as f:\n",
    "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
    "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
    "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
    "AZURE_DATA_NAME = d['config']['AZURE_DATA_NAME']    \n",
    "DATA_DIR = d['config']['DATA_DIR']\n",
    "CLOUD_DIR = d['config']['CLOUD_DIR']\n",
    "HF_MODEL_NAME_OR_PATH = d['config']['HF_MODEL_NAME_OR_PATH']\n",
    "\n",
    "azure_env_name = d['train']['azure_env_name']\n",
    "azure_compute_cluster_name = d['train']['azure_compute_cluster_name']\n",
    "azure_compute_cluster_size = d['train']['azure_compute_cluster_size']\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CLOUD_DIR, exist_ok=True)\n",
    "\n",
    "logger.info(\"===== 0. Azure ML Training Info =====\")\n",
    "logger.info(f\"AZURE_SUBSCRIPTION_ID={AZURE_SUBSCRIPTION_ID}\")\n",
    "logger.info(f\"AZURE_RESOURCE_GROUP={AZURE_RESOURCE_GROUP}\")\n",
    "logger.info(f\"AZURE_WORKSPACE={AZURE_WORKSPACE}\")\n",
    "logger.info(f\"AZURE_DATA_NAME={AZURE_DATA_NAME}\")\n",
    "logger.info(f\"DATA_DIR={DATA_DIR}\")\n",
    "logger.info(f\"CLOUD_DIR={CLOUD_DIR}\")\n",
    "logger.info(f\"HF_MODEL_NAME_OR_PATH={HF_MODEL_NAME_OR_PATH}\")\n",
    "\n",
    "logger.info(f\"azure_env_name={azure_env_name}\")\n",
    "logger.info(f\"azure_compute_cluster_name={azure_compute_cluster_name}\")\n",
    "logger.info(f\"azure_compute_cluster_size={azure_compute_cluster_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure workspace details\n",
    "\n",
    "To connect to a workspace, we need identifying parameters - a subscription, a resource group, and a workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle on the Azure Machine Learning workspace we need. We will use the default Azure authentication for this hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 16:02:32,572 - logger - INFO - ===== 2. Training preparation =====\n",
      "2025-02-26 16:02:32,573 - logger - INFO - Calling DefaultAzureCredential.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f055e126050>,\n",
       "         subscription_id=49aee8bf-3f02-464f-a0ba-e3467e7d85e2,\n",
       "         resource_group_name=rg-slmwrkshp_9,\n",
       "         workspace_name=mlw-pgwgybluulpec)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml import Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
    "\n",
    "logger.info(f\"===== 2. Training preparation =====\")\n",
    "logger.info(f\"Calling DefaultAzureCredential.\")\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)  # 创建AML workspace client, 其实一个AIF ai prj就对应了一个AML wrkspac\n",
    "ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Dataset preparation\n",
    "\n",
    "---\n",
    "\n",
    "Preparing dataset is the first step in training a model. You can use the `datasets` library to load the dataset if you want to use Hugging Face datasets.<br>\n",
    "Otherwise, you can use your own dataset from previous hands-on sessions.\n",
    "\n",
    "We have prepared a dataset, [`lab1_augmented_samples.json`](lab1_augmented_samples.json), for this hands-on session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE_HF_DATASETS = False # Determine if we use Hugging Face Datasets or not\n",
    "\n",
    "# import json\n",
    "# import random\n",
    "# from datasets import load_dataset\n",
    "# from random import randrange\n",
    "# from logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 13:48:37,357 - logger - INFO - ===== 1. Custom Dataset preparation from Lab 1.  =====\n",
      "2025-01-08 13:48:37,359 - logger - INFO - Preparing dataset.\n",
      "2025-01-08 13:48:37,801 - logger - INFO - Save dataset to ./dataset\n"
     ]
    }
   ],
   "source": [
    "# if not USE_HF_DATASETS:\n",
    "\n",
    "#     # Function to load data from the provided file and convert to JSONL format for single-turn conversations\n",
    "#     def load_and_convert_to_jsonl(file_path, system_prompt_msg=\"You're an AI assistant.\"):\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "        \n",
    "#         result = []\n",
    "        \n",
    "#         for item in data:\n",
    "#             jsonl_entry = {\n",
    "#                 \"prompt\": system_prompt_msg,\n",
    "#                 \"messages\": [\n",
    "#                     {\"content\": item[\"input\"], \"role\": \"user\"},\n",
    "#                     {\"content\": item[\"output\"], \"role\": \"assistant\"}\n",
    "#                 ]\n",
    "#             }\n",
    "#             result.append(json.dumps(jsonl_entry))\n",
    "        \n",
    "#         return result\n",
    "\n",
    "#     def save_jsonl_data(jsonl_data, file_path):\n",
    "#         with open(file_path, 'w') as file:\n",
    "#             for entry in jsonl_data:\n",
    "#                 file.write(entry + '\\n')\n",
    "                \n",
    "#     # Function to split data into training and testing sets\n",
    "#     def split_train_test(jsonl_data, train_size=0.8):\n",
    "#         # Shuffle the data\n",
    "#         random.shuffle(jsonl_data)\n",
    "        \n",
    "#         # Calculate split index\n",
    "#         split_index = int(len(jsonl_data) * train_size)\n",
    "        \n",
    "#         # Split the data\n",
    "#         train_data = jsonl_data[:split_index]\n",
    "#         test_data = jsonl_data[split_index:]\n",
    "        \n",
    "#         return train_data, test_data            \n",
    "\n",
    "#     logger.info(f\"===== 1. Custom Dataset preparation from Lab 1.  =====\")\n",
    "#     logger.info(f\"Preparing dataset.\")\n",
    "#     file_path = \"lab1_augmented_samples.json\"\n",
    "#     system_prompt_msg = \"You are the SME (Subject Matter Expert) in Distributed training on Cloud. Please answer the questions accurately.\"\n",
    "#     jsonl_dataset = load_and_convert_to_jsonl(file_path, system_prompt_msg) # 转成训练数据的格式\n",
    "#     train_dataset, test_dataset = split_train_test(jsonl_dataset, train_size=0.8)\n",
    "#     logger.info(f\"Save dataset to {DATA_DIR}\")\n",
    "#     save_jsonl_data(train_dataset, f\"{DATA_DIR}/train.jsonl\")\n",
    "#    save_jsonl_data(test_dataset, f\"{DATA_DIR}/eval.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data can be used as a dataset stored in the local development environment, but can also be registered as AzureML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_data_asset(ml_client, data_name, data_local_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_data_version = max([int(d.version) for d in ml_client.data.list(name=data_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Data asset, but will update the Data.')            \n",
    "        else:\n",
    "            data_asset = ml_client.data.get(name=data_name, version=latest_data_version)\n",
    "            logger.info(f\"Found Data asset: {data_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        data = Data(\n",
    "            path=data_local_dir,\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            description=f\"{data_name} for fine tuning\",\n",
    "            tags={\"FineTuningType\": \"Instruction\", \"Language\": \"En\"},\n",
    "            name=data_name\n",
    "        )\n",
    "        data_asset = ml_client.data.create_or_update(data)#AIF/AiPrj/Data+idx中；AML对应的wrkspac/Data中\n",
    "        logger.info(f\"Created/Updated Data asset: {data_name}\")\n",
    "        \n",
    "    return data_asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading dataset (0.03 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31660/31660 [00:00<00:00, 1213041.61it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "2025-02-26 00:43:11,597 - logger - INFO - Created/Updated Data asset: lgds-gsm8k-main-demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_context:\n",
      "  created_at: '2025-02-26T00:43:11.477091+00:00'\n",
      "  created_by: Gang Luo\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2025-02-26T00:43:11.487717+00:00'\n",
      "description: lgds-gsm8k-main-demo for fine tuning\n",
      "id: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/data/lgds-gsm8k-main-demo/versions/1\n",
      "name: lgds-gsm8k-main-demo\n",
      "path: azureml://subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec/datastores/workspaceblobstore/paths/LocalUpload/22bb1f97e3eec91f29c1fb50c45854a9/dataset/\n",
      "properties: {}\n",
      "tags:\n",
      "  FineTuningType: Instruction\n",
      "  Language: En\n",
      "type: uri_folder\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We have prepared the data in `./dataset`. And the data is extracted from ·openai/gsm8k· using `./dataset-preparation/datapreparation.py`.\n",
    "\n",
    "data = get_or_create_data_asset(ml_client, AZURE_DATA_NAME, data_local_dir=DATA_DIR, update=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Training preparation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Create AzureML environment\n",
    "Azure ML defines containers (called environment asset) in which your code will run. We can use the built-in environment or build a custom environment (Docker container, conda).\n",
    "This hands-on uses conda yaml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./cloud/train/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CLOUD_DIR}/train/Dockerfile\n",
    "FROM mcr.microsoft.com/aifx/acpt/stable-ubuntu2004-cu124-py310-torch241:biweekly.202410.2\n",
    "\n",
    "USER root\n",
    "\n",
    "RUN apt-get update && apt-get -y upgrade\n",
    "RUN pip install --upgrade pip\n",
    "RUN apt-get install -y openssh-server openssh-client\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt --no-cache-dir\n",
    "Run pip install vllm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./cloud/train/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CLOUD_DIR}/train/requirements.txt\n",
    "azureml-mlflow==1.58.0\n",
    "accelerate==1.4.0\n",
    "beautifulsoup4==4.13.3\n",
    "bitsandbytes==0.45.3\n",
    "datasets==3.3.2\n",
    "deepspeed==0.15.4\n",
    "huggingface_hub==0.29.1\n",
    "latex2sympy2_extended==1.0.6\n",
    "Markdown==3.7\n",
    "math_verify==0.5.2\n",
    "mlflow_skinny==2.15.0\n",
    "numpy~=1.23.5\n",
    "openai==1.64.0\n",
    "packaging==24.2\n",
    "pandas==2.2.3\n",
    "peft==0.14.0\n",
    "python-dotenv==1.0.1\n",
    "safetensors==0.5.2\n",
    "torch==2.5.1\n",
    "tqdm==4.66.4\n",
    "transformers==4.48.2\n",
    "trl==0.15.1\n",
    "unsloth==2025.2.15\n",
    "unsloth_zoo==2025.2.7\n",
    "wandb==0.19.7\n",
    "azureml-sdk==1.58.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_or_create_docker_environment_asset(ml_client, env_name, docker_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
    "        else:\n",
    "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
    "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")\n",
    "        env_docker_image = Environment(\n",
    "            build=BuildContext(path=docker_dir),\n",
    "            name=env_name,\n",
    "            description=\"Environment created from a Docker context.\",\n",
    "        )\n",
    "        env_asset = ml_client.environments.create_or_update(env_docker_image)#AIF没有,但AIF/Code有用到一个内置的env。真身在AML对应的wrkspac/Environments中\n",
    "        logger.info(f\"Created Environment asset: {env_name}\")\n",
    "    \n",
    "    return env_asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 20:19:21,115 - logger - INFO - Exception: Found Environment asset, but will update the Environment.\n",
      "\u001b[32mUploading train (0.0 MBs): 100%|██████████| 1158/1158 [00:01<00:00, 640.94it/s]\n",
      "\u001b[39m\n",
      "\n",
      "2025-02-26 20:19:42,330 - logger - INFO - Created Environment asset: llm-sft-2024-11-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'llm-sft-2024-11-05', 'description': 'Environment created from a Docker context.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/environments/llm-sft-2024-11-05/versions/12', 'Resource__source_path': '', 'base_path': '/mnt/d/BT/SRC/NLP/LLM/O1/reasoningimprove/phi4_rl', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f052919f610>, 'serialize': <msrest.serialization.Serializer object at 0x7f052919de70>, 'version': '12', 'conda_file': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7f052919f310>, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_or_create_docker_environment_asset(ml_client, azure_env_name, docker_dir=f\"{CLOUD_DIR}/train\", update=False)\n",
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Training\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1. Create the compute cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 20:19:42,357 - logger - INFO - ===== 3. Training =====\n",
      "2025-02-26 20:19:43,438 - logger - INFO - The compute cluster already exists! Reusing it for the current run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable_node_public_ip: true\n",
      "id: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/computes/gpu-h100\n",
      "idle_time_before_scale_down: 120\n",
      "location: eastus\n",
      "max_instances: 1\n",
      "min_instances: 0\n",
      "name: gpu-h100\n",
      "network_settings: {}\n",
      "provisioning_state: Succeeded\n",
      "size: Standard_NC40ads_H100_v5\n",
      "ssh_public_access_enabled: true\n",
      "tier: dedicated\n",
      "type: amlcompute\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "logger.info(f\"===== 3. Training =====\")\n",
    "### Create the compute cluster\n",
    "try:\n",
    "    compute = ml_client.compute.get(azure_compute_cluster_name)\n",
    "    logger.info(\"The compute cluster already exists! Reusing it for the current run\")\n",
    "except Exception as ex:\n",
    "    logger.info(\n",
    "        f\"Looks like the compute cluster doesn't exist. Creating a new one with compute size {azure_compute_cluster_size}!\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Attempt #1 - Trying to create a dedicated compute\")\n",
    "        tier = 'Dedicated'\n",
    "        compute = AmlCompute(\n",
    "            name=azure_compute_cluster_name,\n",
    "            size=azure_compute_cluster_size, # Standard_NC40ads_H100_v5\n",
    "            tier=tier,\n",
    "            max_instances=1,  # For multi node training set this to an integer value more than 1\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute).wait()#AIF/ai prj/->management center/对应的hub那一组菜单项/Compute。要修改Compute所需的CPU/GPU Quota则在同一个management center页面菜单中选择Quota\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error: {e}\")\n",
    "print(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize src_train/train_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Start training job\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "\n",
    "-   `inputs` - This is the dictionary of inputs using name value pairs to the command.\n",
    "    -   `type` - The type of input. This can be a `uri_file` or `uri_folder`. The default is `uri_folder`.\n",
    "    -   `path` - The path to the file or folder. These can be local or remote files or folders. For remote files - http/https, wasb are supported.\n",
    "        -   Azure ML `data`/`dataset` or `datastore` are of type `uri_folder`. To use `data`/`dataset` as input, you can use registered dataset in the workspace using the format '<data_name>:<version>'. For e.g Input(type='uri_folder', path='my_dataset:1')\n",
    "    -   `mode` - Mode of how the data should be delivered to the compute target. Allowed values are `ro_mount`, `rw_mount` and `download`. Default is `ro_mount`\n",
    "-   `code` - This is the path where the code to run the command is located\n",
    "-   `compute` - The compute on which the command will run. You can run it on the local machine by using `local` for the compute.\n",
    "-   `command` - This is the command that needs to be run\n",
    "    in the `command` using the `${{inputs.<input_name>}}` expression. To use files or folders as inputs, we can use the `Input` class. The `Input` class supports three parameters:\n",
    "-   `environment` - This is the environment needed for the command to run. Curated (built-in) or custom environments from the workspace can be used.\n",
    "-   `instance_count` - Number of nodes. Default is 1.\n",
    "-   `distribution` - Distribution configuration for distributed training scenarios. Azure Machine Learning supports PyTorch, TensorFlow, and MPI-based distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 20:19:43,478 - logger - INFO - Env: llm-sft-2024-11-05@latest\n",
      "2025-02-26 20:19:43,482 - logger - INFO - Command: python train_mlflow.py             --train_dir ${{inputs.train_dir}}             --model_dir ${{inputs.model_dir}}\n",
      "2025-02-26 20:19:51,399 - logger - INFO - Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
      "required for training is automatically set up from Environment.\n",
      "\n",
      "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: happy_gold_q5lypvqkw5\n",
      "Web View: https://ml.azure.com/runs/happy_gold_q5lypvqkw5?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "======Starting Image Build on Serverless Compute======\n",
      "The run ID for the image build on serverless compute is imgbldrun_dfabf2a\n",
      "Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_dfabf2a?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "2025-02-26T12:20:04: Logging into Docker registry: f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io\n",
      "2025-02-26T12:20:04: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-02-26T12:20:04: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "2025-02-26T12:20:04: Configure a credential helper to remove this warning. See\n",
      "2025-02-26T12:20:04: https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "2025-02-26T12:20:04: Login Succeeded\n",
      "\n",
      "\n",
      "2025-02-26T12:20:04: Running: ['docker', 'build', '-f', 'Dockerfile', '.', '-t', 'f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415', '-t', 'f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415:1']\n",
      "2025-02-26T12:20:04: DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n",
      "2025-02-26T12:20:04:             Install the buildx component to build images with BuildKit:\n",
      "2025-02-26T12:20:04:             https://docs.docker.com/go/buildx/\n",
      "\n",
      "2025-02-26T12:20:04: Sending build context to Docker daemon  4.096kB\n",
      "2025-02-26T12:20:04: Step 1/8 : FROM mcr.microsoft.com/aifx/acpt/stable-ubuntu2004-cu124-py310-torch241:biweekly.202410.2\n",
      "2025-02-26T12:20:04:  ---> 085c07d4bcf3\n",
      "2025-02-26T12:20:04: Step 2/8 : USER root\n",
      "2025-02-26T12:20:04:  ---> Using cache\n",
      "2025-02-26T12:20:04:  ---> 303fee76a094\n",
      "2025-02-26T12:20:04: Step 3/8 : RUN apt-get update && apt-get -y upgrade\n",
      "2025-02-26T12:20:04:  ---> Using cache\n",
      "2025-02-26T12:20:04:  ---> 9b71f384b9fe\n",
      "2025-02-26T12:20:04: Step 4/8 : RUN pip install --upgrade pip\n",
      "2025-02-26T12:20:04:  ---> Using cache\n",
      "2025-02-26T12:20:04:  ---> 5a7fd0823d61\n",
      "2025-02-26T12:20:04: Step 5/8 : RUN apt-get install -y openssh-server openssh-client\n",
      "2025-02-26T12:20:04:  ---> Using cache\n",
      "2025-02-26T12:20:04:  ---> 95350f67cf67\n",
      "2025-02-26T12:20:04: Step 6/8 : COPY requirements.txt .\n",
      "2025-02-26T12:20:08:  ---> 7d2d9ca81f72\n",
      "2025-02-26T12:20:08: Step 7/8 : RUN pip install -r requirements.txt --no-cache-dir\n",
      "2025-02-26T12:20:08:  ---> Running in ee5a5f0b726f\n",
      "2025-02-26T12:20:09: Collecting azureml-mlflow==1.58.0 (from -r requirements.txt (line 1))\n",
      "2025-02-26T12:20:09:   Downloading azureml_mlflow-1.58.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-02-26T12:20:09: Collecting accelerate==1.4.0 (from -r requirements.txt (line 2))\n",
      "2025-02-26T12:20:09:   Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-02-26T12:20:09: Collecting beautifulsoup4==4.13.3 (from -r requirements.txt (line 3))\n",
      "2025-02-26T12:20:09:   Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-02-26T12:20:09: Collecting bitsandbytes==0.45.3 (from -r requirements.txt (line 4))\n",
      "2025-02-26T12:20:09:   Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "2025-02-26T12:20:09: Collecting datasets==3.3.2 (from -r requirements.txt (line 5))\n",
      "2025-02-26T12:20:09:   Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "2025-02-26T12:20:09: Collecting deepspeed==0.15.4 (from -r requirements.txt (line 6))\n",
      "2025-02-26T12:20:09:   Downloading deepspeed-0.15.4.tar.gz (1.4 MB)\n",
      "2025-02-26T12:20:09:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 131.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:10:   Preparing metadata (setup.py): started\n",
      "2025-02-26T12:20:19:   Preparing metadata (setup.py): finished with status 'done'\n",
      "2025-02-26T12:20:19: Collecting huggingface_hub==0.29.1 (from -r requirements.txt (line 7))\n",
      "2025-02-26T12:20:19:   Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:20:19: Collecting latex2sympy2_extended==1.0.6 (from -r requirements.txt (line 8))\n",
      "2025-02-26T12:20:19:   Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "2025-02-26T12:20:19: Collecting Markdown==3.7 (from -r requirements.txt (line 9))\n",
      "2025-02-26T12:20:19:   Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "2025-02-26T12:20:19: Collecting math_verify==0.5.2 (from -r requirements.txt (line 10))\n",
      "2025-02-26T12:20:19:   Downloading math_verify-0.5.2-py3-none-any.whl.metadata (347 bytes)\n",
      "2025-02-26T12:20:19: Collecting mlflow_skinny==2.15.0 (from -r requirements.txt (line 11))\n",
      "2025-02-26T12:20:19:   Downloading mlflow_skinny-2.15.0-py3-none-any.whl.metadata (30 kB)\n",
      "2025-02-26T12:20:19: Requirement already satisfied: numpy in /opt/conda/envs/ptca/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.24.4)\n",
      "2025-02-26T12:20:19: Collecting openai==1.64.0 (from -r requirements.txt (line 13))\n",
      "2025-02-26T12:20:19:   Downloading openai-1.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "2025-02-26T12:20:19: Collecting packaging==24.2 (from -r requirements.txt (line 14))\n",
      "2025-02-26T12:20:19:   Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-02-26T12:20:19: Collecting pandas==2.2.3 (from -r requirements.txt (line 15))\n",
      "2025-02-26T12:20:19:   Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "2025-02-26T12:20:19: Collecting peft==0.14.0 (from -r requirements.txt (line 16))\n",
      "2025-02-26T12:20:19:   Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:20:19: Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 17))\n",
      "2025-02-26T12:20:19:   Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "2025-02-26T12:20:19: Collecting safetensors==0.5.2 (from -r requirements.txt (line 18))\n",
      "2025-02-26T12:20:19:   Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "2025-02-26T12:20:19: Collecting torch==2.5.1 (from -r requirements.txt (line 19))\n",
      "2025-02-26T12:20:19:   Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "2025-02-26T12:20:19: Collecting tqdm==4.66.4 (from -r requirements.txt (line 20))\n",
      "2025-02-26T12:20:19:   Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "2025-02-26T12:20:19: Collecting transformers==4.48.2 (from -r requirements.txt (line 21))\n",
      "2025-02-26T12:20:19:   Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "2025-02-26T12:20:19: Collecting trl==0.15.1 (from -r requirements.txt (line 22))\n",
      "2025-02-26T12:20:19:   Downloading trl-0.15.1-py3-none-any.whl.metadata (11 kB)\n",
      "2025-02-26T12:20:20: Collecting unsloth==2025.2.15 (from -r requirements.txt (line 23))\n",
      "2025-02-26T12:20:20:   Downloading unsloth-2025.2.15-py3-none-any.whl.metadata (57 kB)\n",
      "2025-02-26T12:20:20: Collecting unsloth_zoo==2025.2.7 (from -r requirements.txt (line 24))\n",
      "2025-02-26T12:20:20:   Downloading unsloth_zoo-2025.2.7-py3-none-any.whl.metadata (16 kB)\n",
      "2025-02-26T12:20:20: Collecting wandb==0.19.7 (from -r requirements.txt (line 25))\n",
      "2025-02-26T12:20:20:   Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "2025-02-26T12:20:20: Collecting azureml-sdk==1.58.0 (from -r requirements.txt (line 26))\n",
      "2025-02-26T12:20:20:   Downloading azureml_sdk-1.58.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "2025-02-26T12:20:20: Collecting jsonpickle (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading jsonpickle-4.0.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: azure-identity in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (1.19.0)\n",
      "2025-02-26T12:20:20: Collecting msrest>=0.6.18 (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: azure-core!=1.22.0,<2.0.0,>=1.8.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (1.31.0)\n",
      "2025-02-26T12:20:20: Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-02-26T12:20:20: Collecting azure-storage-blob<=12.19.0,>=12.5.0 (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "2025-02-26T12:20:20: Collecting azure-common<2.0.0,>=1.1 (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: cryptography in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (43.0.3)\n",
      "2025-02-26T12:20:20: Collecting python-dateutil<3.0.0,>=2.7.3 (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:20:   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: psutil in /opt/conda/envs/ptca/lib/python3.10/site-packages (from accelerate==1.4.0->-r requirements.txt (line 2)) (6.1.0)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: pyyaml in /opt/conda/envs/ptca/lib/python3.10/site-packages (from accelerate==1.4.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "2025-02-26T12:20:20: Collecting soupsieve>1.2 (from beautifulsoup4==4.13.3->-r requirements.txt (line 3))\n",
      "2025-02-26T12:20:20:   Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from beautifulsoup4==4.13.3->-r requirements.txt (line 3)) (4.12.2)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: filelock in /opt/conda/envs/ptca/lib/python3.10/site-packages (from datasets==3.3.2->-r requirements.txt (line 5)) (3.16.1)\n",
      "2025-02-26T12:20:20: Collecting pyarrow>=15.0.0 (from datasets==3.3.2->-r requirements.txt (line 5))\n",
      "2025-02-26T12:20:20:   Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "2025-02-26T12:20:20: Collecting dill<0.3.9,>=0.3.0 (from datasets==3.3.2->-r requirements.txt (line 5))\n",
      "2025-02-26T12:20:20:   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: requests>=2.32.2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from datasets==3.3.2->-r requirements.txt (line 5)) (2.32.3)\n",
      "2025-02-26T12:20:20: Collecting xxhash (from datasets==3.3.2->-r requirements.txt (line 5))\n",
      "2025-02-26T12:20:20:   Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "2025-02-26T12:20:20: Collecting multiprocess<0.70.17 (from datasets==3.3.2->-r requirements.txt (line 5))\n",
      "2025-02-26T12:20:20:   Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.3.2->-r requirements.txt (line 5)) (2024.10.0)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: aiohttp in /opt/conda/envs/ptca/lib/python3.10/site-packages (from datasets==3.3.2->-r requirements.txt (line 5)) (3.10.10)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: hjson in /opt/conda/envs/ptca/lib/python3.10/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 6)) (3.1.0)\n",
      "2025-02-26T12:20:20: Collecting msgpack (from deepspeed==0.15.4->-r requirements.txt (line 6))\n",
      "2025-02-26T12:20:20:   Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: ninja in /opt/conda/envs/ptca/lib/python3.10/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 6)) (1.11.1)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: py-cpuinfo in /opt/conda/envs/ptca/lib/python3.10/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 6)) (9.0.0)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: pydantic>=2.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 6)) (2.9.2)\n",
      "2025-02-26T12:20:20: Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended==1.0.6->-r requirements.txt (line 8))\n",
      "2025-02-26T12:20:20:   Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: sympy in /opt/conda/envs/ptca/lib/python3.10/site-packages (from latex2sympy2_extended==1.0.6->-r requirements.txt (line 8)) (1.13.3)\n",
      "2025-02-26T12:20:20: Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (5.5.0)\n",
      "2025-02-26T12:20:20: Collecting click<9,>=7.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:20:   Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-02-26T12:20:20: Collecting cloudpickle<4 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:20:   Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-02-26T12:20:20: Collecting databricks-sdk<1,>=0.20.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:20:   Downloading databricks_sdk-0.44.1-py3-none-any.whl.metadata (38 kB)\n",
      "2025-02-26T12:20:20: Collecting entrypoints<1 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:20:   Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-02-26T12:20:20: Collecting gitpython<4,>=3.1.9 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:20:   Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:20:21: Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:21:   Downloading importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-02-26T12:20:21: Collecting opentelemetry-api<3,>=1.9.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:21:   Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:21:   Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (3.20.3)\n",
      "2025-02-26T12:20:21: Collecting pytz<2025 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:21:   Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "2025-02-26T12:20:21: Collecting sqlparse<1,>=0.4.0 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:21:   Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "2025-02-26T12:20:21: Collecting anyio<5,>=3.5.0 (from openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:21:   Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-02-26T12:20:21: Collecting distro<2,>=1.7.0 (from openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:21:   Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-02-26T12:20:21: Collecting httpx<1,>=0.23.0 (from openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:21:   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-02-26T12:20:21: Collecting jiter<1,>=0.4.0 (from openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:21:   Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "2025-02-26T12:20:21: Collecting sniffio (from openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:21:   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "2025-02-26T12:20:21: Collecting tzdata>=2022.7 (from pandas==2.2.3->-r requirements.txt (line 15))\n",
      "2025-02-26T12:20:21:   Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-02-26T12:20:21: Requirement already satisfied: networkx in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->-r requirements.txt (line 19)) (3.4.2)\n",
      "2025-02-26T12:20:21: Requirement already satisfied: jinja2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->-r requirements.txt (line 19)) (3.1.4)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "2025-02-26T12:20:21: Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "2025-02-26T12:20:21: Collecting triton==3.1.0 (from torch==2.5.1->-r requirements.txt (line 19))\n",
      "2025-02-26T12:20:21:   Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "2025-02-26T12:20:21: Collecting sympy (from latex2sympy2_extended==1.0.6->-r requirements.txt (line 8))\n",
      "2025-02-26T12:20:21:   Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "2025-02-26T12:20:21: Collecting regex!=2019.12.17 (from transformers==4.48.2->-r requirements.txt (line 21))\n",
      "2025-02-26T12:20:21:   Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "2025-02-26T12:20:21: Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.2->-r requirements.txt (line 21))\n",
      "2025-02-26T12:20:21:   Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "2025-02-26T12:20:21: Collecting rich (from trl==0.15.1->-r requirements.txt (line 22))\n",
      "2025-02-26T12:20:21:   Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "2025-02-26T12:20:22: Collecting xformers>=0.0.27.post2 (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "2025-02-26T12:20:22: Collecting tyro (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\n",
      "2025-02-26T12:20:22: Collecting sentencepiece>=0.2.0 (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "2025-02-26T12:20:22: Collecting wheel>=0.42.0 (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-02-26T12:20:22: Collecting hf_transfer (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "2025-02-26T12:20:22: Collecting diffusers (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:22:   Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: torchvision in /opt/conda/envs/ptca/lib/python3.10/site-packages (from unsloth==2025.2.15->-r requirements.txt (line 23)) (0.19.1+cu124)\n",
      "2025-02-26T12:20:22: Collecting cut_cross_entropy (from unsloth_zoo==2025.2.7->-r requirements.txt (line 24))\n",
      "2025-02-26T12:20:22:   Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: pillow in /opt/conda/envs/ptca/lib/python3.10/site-packages (from unsloth_zoo==2025.2.7->-r requirements.txt (line 24)) (11.0.0)\n",
      "2025-02-26T12:20:22: Collecting docker-pycreds>=0.4.0 (from wandb==0.19.7->-r requirements.txt (line 25))\n",
      "2025-02-26T12:20:22:   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:20:22: Collecting platformdirs (from wandb==0.19.7->-r requirements.txt (line 25))\n",
      "2025-02-26T12:20:22:   Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "2025-02-26T12:20:22: Collecting sentry-sdk>=2.0.0 (from wandb==0.19.7->-r requirements.txt (line 25))\n",
      "2025-02-26T12:20:22:   Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "2025-02-26T12:20:22: Collecting setproctitle (from wandb==0.19.7->-r requirements.txt (line 25))\n",
      "2025-02-26T12:20:22:   Downloading setproctitle-1.3.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: setuptools in /opt/conda/envs/ptca/lib/python3.10/site-packages (from wandb==0.19.7->-r requirements.txt (line 25)) (72.1.0)\n",
      "2025-02-26T12:20:22: Collecting azureml-core~=1.58.0 (from azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_core-1.58.0.post1-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-02-26T12:20:22: Collecting azureml-dataset-runtime~=1.58.0 (from azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_dataset_runtime-1.58.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-02-26T12:20:22: Collecting azureml-train-core~=1.58.0 (from azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_train_core-1.58.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:20:22: Collecting azureml-train-automl-client~=1.58.0 (from azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_train_automl_client-1.58.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-02-26T12:20:22: Collecting azureml-pipeline~=1.58.0 (from azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_pipeline-1.58.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from sympy->latex2sympy2_extended==1.0.6->-r requirements.txt (line 8)) (1.3.0)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.64.0->-r requirements.txt (line 13)) (1.2.2)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: idna>=2.8 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.64.0->-r requirements.txt (line 13)) (3.10)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: six>=1.11.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "2025-02-26T12:20:22: Collecting isodate>=0.6.1 (from azure-storage-blob<=12.19.0,>=12.5.0->azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:22:   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "2025-02-26T12:20:22: Collecting backports.tempfile (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-02-26T12:20:22: Collecting pathspec<1.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: msal<2.0.0,>=1.15.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (1.31.0)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (1.2.0)\n",
      "2025-02-26T12:20:22: Collecting knack<0.13.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "2025-02-26T12:20:22: Collecting pkginfo (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: argcomplete<4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (3.5.1)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: humanfriendly<11.0,>=4.7 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (10.0)\n",
      "2025-02-26T12:20:22: Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_resource-23.3.0-py3-none-any.whl.metadata (41 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl.metadata (23 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-storage<=22.0.0,>=16.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_storage-22.0.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl.metadata (15 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-mgmt-network<=28.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_mgmt_network-28.0.0-py3-none-any.whl.metadata (86 kB)\n",
      "2025-02-26T12:20:22: Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-02-26T12:20:22: Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: urllib3<3.0.0,>1.26.17 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (2.2.3)\n",
      "2025-02-26T12:20:22: Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-02-26T12:20:22: Collecting SecretStorage<4.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-02-26T12:20:22: Collecting jsonpickle (from azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:22:   Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "2025-02-26T12:20:22: Collecting contextlib2<22.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "2025-02-26T12:20:22: Collecting docker<8.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-02-26T12:20:22: Requirement already satisfied: PyJWT<3.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (2.9.0)\n",
      "2025-02-26T12:20:22: Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-02-26T12:20:22: Collecting pyopenssl<25.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading pyOpenSSL-24.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-02-26T12:20:22: Collecting jmespath<2.0.0 (from azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-02-26T12:20:22: Collecting azureml-dataprep<5.2.0a,>=5.1.0a (from azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:22:   Downloading azureml_dataprep-5.1.6-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-02-26T12:20:23: Collecting numpy (from -r requirements.txt (line 12))\n",
      "2025-02-26T12:20:23:   Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "2025-02-26T12:20:23: Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "2025-02-26T12:20:23:   Preparing metadata (setup.py): started\n",
      "2025-02-26T12:20:23:   Preparing metadata (setup.py): finished with status 'done'\n",
      "2025-02-26T12:20:23: Collecting azureml-pipeline-core~=1.58.0 (from azureml-pipeline~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading azureml_pipeline_core-1.58.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "2025-02-26T12:20:23: Collecting azureml-pipeline-steps~=1.58.0 (from azureml-pipeline~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading azureml_pipeline_steps-1.58.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "2025-02-26T12:20:23: Collecting azureml-automl-core~=1.58.0 (from azureml-train-automl-client~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading azureml_automl_core-1.58.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "2025-02-26T12:20:23: Collecting azureml-telemetry~=1.58.0 (from azureml-train-automl-client~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading azureml_telemetry-1.58.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "2025-02-26T12:20:23: Collecting azureml-train-restclients-hyperdrive~=1.58.0 (from azureml-train-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:23:   Downloading azureml_train_restclients_hyperdrive-1.58.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from cryptography->azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (1.17.1)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: google-auth~=2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (2.35.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (2.4.3)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (1.3.1)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (24.2.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (1.5.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (6.1.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (1.16.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (4.0.3)\n",
      "2025-02-26T12:20:23: Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:23:   Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: certifi in /opt/conda/envs/ptca/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.64.0->-r requirements.txt (line 13)) (2024.8.30)\n",
      "2025-02-26T12:20:23: Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:23:   Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "2025-02-26T12:20:23: Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.64.0->-r requirements.txt (line 13))\n",
      "2025-02-26T12:20:23:   Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (3.20.2)\n",
      "2025-02-26T12:20:23: Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.18->azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:23:   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-02-26T12:20:23: Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:23:   Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "2025-02-26T12:20:23: Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:23:   Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.15.4->-r requirements.txt (line 6)) (0.7.0)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.15.4->-r requirements.txt (line 6)) (2.23.4)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.3.2->-r requirements.txt (line 5)) (3.4.0)\n",
      "2025-02-26T12:20:23: INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-02-26T12:20:23: Collecting xformers>=0.0.27.post2 (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:23:   Downloading xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "2025-02-26T12:20:23:   Downloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "2025-02-26T12:20:23: Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from jinja2->torch==2.5.1->-r requirements.txt (line 19)) (3.0.2)\n",
      "2025-02-26T12:20:23: Collecting markdown-it-py>=2.2.0 (from rich->trl==0.15.1->-r requirements.txt (line 22))\n",
      "2025-02-26T12:20:23:   Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-02-26T12:20:23: Collecting pygments<3.0.0,>=2.13.0 (from rich->trl==0.15.1->-r requirements.txt (line 22))\n",
      "2025-02-26T12:20:23:   Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-02-26T12:20:23: INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-02-26T12:20:24: Collecting torchvision (from unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:24:   Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "2025-02-26T12:20:24:   Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "2025-02-26T12:20:24: Collecting docstring-parser>=0.15 (from tyro->unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:24:   Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "2025-02-26T12:20:24: Collecting shtab>=1.5.6 (from tyro->unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:24:   Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "2025-02-26T12:20:24: Collecting typeguard>=4.0.0 (from tyro->unsloth==2025.2.15->-r requirements.txt (line 23))\n",
      "2025-02-26T12:20:24:   Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-02-26T12:20:24: Collecting importlib-resources<=6.4.0 (from azureml-automl-core~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "2025-02-26T12:20:24: Collecting azureml-dataprep-native<42.0.0,>=41.0.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading azureml_dataprep_native-41.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.3 kB)\n",
      "2025-02-26T12:20:24: Collecting azureml-dataprep-rslex~=2.22.2dev0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading azureml_dataprep_rslex-2.22.5-cp310-cp310-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:24: Collecting cloudpickle<4 (from mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:24:   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-02-26T12:20:24: Collecting jsonschema (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "2025-02-26T12:20:24: Collecting applicationinsights (from azureml-telemetry~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading applicationinsights-0.11.10-py2.py3-none-any.whl.metadata (982 bytes)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: pycparser in /opt/conda/envs/ptca/lib/python3.10/site-packages (from cffi>=1.12->cryptography->azureml-mlflow==1.58.0->-r requirements.txt (line 1)) (2.22)\n",
      "2025-02-26T12:20:24: Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:24:   Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "2025-02-26T12:20:24: Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow_skinny==2.15.0->-r requirements.txt (line 11))\n",
      "2025-02-26T12:20:24:   Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (0.4.1)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow_skinny==2.15.0->-r requirements.txt (line 11)) (4.9)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: tabulate in /opt/conda/envs/ptca/lib/python3.10/site-packages (from knack<0.13.0->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (0.9.0)\n",
      "2025-02-26T12:20:24: Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl==0.15.1->-r requirements.txt (line 22))\n",
      "2025-02-26T12:20:24:   Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: portalocker<3,>=1.4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (2.10.1)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: pyasn1>=0.1.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26)) (0.6.1)\n",
      "2025-02-26T12:20:24: Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "2025-02-26T12:20:24: Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
      "2025-02-26T12:20:24: Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azureml-mlflow==1.58.0->-r requirements.txt (line 1))\n",
      "2025-02-26T12:20:24:   Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "2025-02-26T12:20:24: Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:20:24: Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "2025-02-26T12:20:24: Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==3.3.2->-r requirements.txt (line 5)) (0.2.0)\n",
      "2025-02-26T12:20:24: Collecting backports.weakref (from backports.tempfile->azureml-core~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-02-26T12:20:24: Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "2025-02-26T12:20:24: Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:24:   Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-02-26T12:20:25: Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk==1.58.0->-r requirements.txt (line 26))\n",
      "2025-02-26T12:20:25:   Downloading rpds_py-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-02-26T12:20:25: Downloading azureml_mlflow-1.58.0-py3-none-any.whl (1.0 MB)\n",
      "2025-02-26T12:20:25:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 186.7 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:25: Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
      "2025-02-26T12:20:25: Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "2025-02-26T12:20:25: Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "2025-02-26T12:20:25:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.1/76.1 MB 313.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:25: Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "2025-02-26T12:20:25: Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "2025-02-26T12:20:25: Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n",
      "2025-02-26T12:20:25: Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "2025-02-26T12:20:25: Downloading math_verify-0.5.2-py3-none-any.whl (27 kB)\n",
      "2025-02-26T12:20:25: Downloading mlflow_skinny-2.15.0-py3-none-any.whl (5.5 MB)\n",
      "2025-02-26T12:20:25:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 266.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:25: Downloading openai-1.64.0-py3-none-any.whl (472 kB)\n",
      "2025-02-26T12:20:25: Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "2025-02-26T12:20:25: Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "2025-02-26T12:20:25:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 224.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:25: Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "2025-02-26T12:20:25: Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "2025-02-26T12:20:25: Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "2025-02-26T12:20:25: Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "2025-02-26T12:20:29:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 243.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:29: Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "2025-02-26T12:20:29: Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "2025-02-26T12:20:29:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 317.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:29: Downloading trl-0.15.1-py3-none-any.whl (318 kB)\n",
      "2025-02-26T12:20:29: Downloading unsloth-2025.2.15-py3-none-any.whl (188 kB)\n",
      "2025-02-26T12:20:29: Downloading unsloth_zoo-2025.2.7-py3-none-any.whl (107 kB)\n",
      "2025-02-26T12:20:29: Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
      "2025-02-26T12:20:29:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.8/20.8 MB 321.9 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:29: Downloading azureml_sdk-1.58.0-py3-none-any.whl (2.7 kB)\n",
      "2025-02-26T12:20:29: Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
      "2025-02-26T12:20:29: Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "2025-02-26T12:20:30:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 312.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:30: Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "2025-02-26T12:20:30:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 270.9 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:30: Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "2025-02-26T12:20:30:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 289.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:30: Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "2025-02-26T12:20:30:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 600.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:30: Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "2025-02-26T12:20:32:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 328.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:32: Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "2025-02-26T12:20:33:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 308.5 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:33: Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "2025-02-26T12:20:33:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 318.5 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:33: Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "2025-02-26T12:20:34:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 325.9 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:34: Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "2025-02-26T12:20:34:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 325.9 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:34: Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "2025-02-26T12:20:35:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 327.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:35: Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "2025-02-26T12:20:35:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 312.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:35: Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "2025-02-26T12:20:35: Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "2025-02-26T12:20:35:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 321.4 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:35: Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 293.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "2025-02-26T12:20:36: Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
      "2025-02-26T12:20:36: Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_core-1.58.0.post1-py3-none-any.whl (3.3 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 251.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azureml_dataset_runtime-1.58.0-py3-none-any.whl (2.2 kB)\n",
      "2025-02-26T12:20:36: Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 281.0 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azureml_pipeline-1.58.0-py3-none-any.whl (2.4 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_train_automl_client-1.58.0-py3-none-any.whl (137 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_train_core-1.58.0-py3-none-any.whl (8.6 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 160.5 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "2025-02-26T12:20:36: Downloading databricks_sdk-0.44.1-py3-none-any.whl (648 kB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 648.7/648.7 kB 488.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "2025-02-26T12:20:36: Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "2025-02-26T12:20:36: Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "2025-02-26T12:20:36: Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "2025-02-26T12:20:36: Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "2025-02-26T12:20:36: Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "2025-02-26T12:20:36: Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "2025-02-26T12:20:36: Downloading importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "2025-02-26T12:20:36: Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "2025-02-26T12:20:36: Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "2025-02-26T12:20:36: Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "2025-02-26T12:20:36: Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "2025-02-26T12:20:36: Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "2025-02-26T12:20:36: Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "2025-02-26T12:20:36: Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "2025-02-26T12:20:36: Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 312.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "2025-02-26T12:20:36: Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "2025-02-26T12:20:36: Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 507.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 400.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "2025-02-26T12:20:36: Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "2025-02-26T12:20:36: Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "2025-02-26T12:20:36: Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "2025-02-26T12:20:36: Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 322.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "2025-02-26T12:20:36: Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "2025-02-26T12:20:36: Downloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 251.5 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "2025-02-26T12:20:36: Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 305.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 275.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "2025-02-26T12:20:36: Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "2025-02-26T12:20:36: Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "2025-02-26T12:20:36: Downloading setproctitle-1.3.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "2025-02-26T12:20:36: Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 256.0 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading tyro-0.9.16-py3-none-any.whl (117 kB)\n",
      "2025-02-26T12:20:36: Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "2025-02-26T12:20:36: Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "2025-02-26T12:20:36: Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 278.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl (2.3 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 305.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl (901 kB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 901.4/901.4 kB 331.0 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_network-28.0.0-py3-none-any.whl (548 kB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 548.7/548.7 kB 392.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_resource-23.3.0-py3-none-any.whl (2.9 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 277.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azure_mgmt_storage-22.0.0-py3-none-any.whl (564 kB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 564.0/564.0 kB 544.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading azureml_automl_core-1.58.0-py3-none-any.whl (249 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_dataprep-5.1.6-py3-none-any.whl (252 kB)\n",
      "2025-02-26T12:20:36: Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_pipeline_core-1.58.0-py3-none-any.whl (313 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_pipeline_steps-1.58.0-py3-none-any.whl (69 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_telemetry-1.58.0-py3-none-any.whl (30 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_train_restclients_hyperdrive-1.58.0-py3-none-any.whl (18 kB)\n",
      "2025-02-26T12:20:36: Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "2025-02-26T12:20:36: Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "2025-02-26T12:20:36: Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "2025-02-26T12:20:36: Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "2025-02-26T12:20:36: Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "2025-02-26T12:20:36: Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "2025-02-26T12:20:36: Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "2025-02-26T12:20:36: Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
      "2025-02-26T12:20:36: Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "2025-02-26T12:20:36: Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
      "2025-02-26T12:20:36: Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "2025-02-26T12:20:36: Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "2025-02-26T12:20:36: Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "2025-02-26T12:20:36: Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
      "2025-02-26T12:20:36:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 330.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:36: Downloading pyOpenSSL-24.3.0-py3-none-any.whl (56 kB)\n",
      "2025-02-26T12:20:36: Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "2025-02-26T12:20:36: Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "2025-02-26T12:20:36: Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "2025-02-26T12:20:36: Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "2025-02-26T12:20:36: Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "2025-02-26T12:20:36: Downloading pkginfo-1.12.1.2-py3-none-any.whl (32 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_dataprep_native-41.0.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
      "2025-02-26T12:20:36: Downloading azureml_dataprep_rslex-2.22.5-cp310-cp310-manylinux1_x86_64.whl (24.8 MB)\n",
      "2025-02-26T12:20:37:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.8/24.8 MB 233.2 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:37: Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "2025-02-26T12:20:37: Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "2025-02-26T12:20:37: Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "2025-02-26T12:20:37: Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "2025-02-26T12:20:37: Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "2025-02-26T12:20:37: Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "2025-02-26T12:20:37: Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "2025-02-26T12:20:37:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 416.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:20:37: Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "2025-02-26T12:20:37: Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "2025-02-26T12:20:37: Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "2025-02-26T12:20:37: Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "2025-02-26T12:20:37: Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "2025-02-26T12:20:37: Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "2025-02-26T12:20:37: Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "2025-02-26T12:20:37: Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "2025-02-26T12:20:37: Downloading rpds_py-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "2025-02-26T12:20:45: Building wheels for collected packages: deepspeed, fusepy\n",
      "2025-02-26T12:20:45:   Building wheel for deepspeed (setup.py): started\n",
      "2025-02-26T12:20:51:   Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "2025-02-26T12:20:51:   Created wheel for deepspeed: filename=deepspeed-0.15.4-py3-none-any.whl size=1527716 sha256=1d35d71b8ea8de0802d94ba8768f1e4b66c5101364a380fc45190a23e4426033\n",
      "2025-02-26T12:20:51:   Stored in directory: /tmp/pip-ephem-wheel-cache-_aazpdp6/wheels/74/bc/b6/836d7c3e3093e25502fa9248e0be9e943db245f2806ba1cd19\n",
      "2025-02-26T12:20:51:   Building wheel for fusepy (setup.py): started\n",
      "2025-02-26T12:20:51:   Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "2025-02-26T12:20:51:   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10484 sha256=bf0f3cf64324d4d732cb4f5a1a594cc887b99e6022e63aa565288a938c7dbf09\n",
      "2025-02-26T12:20:51:   Stored in directory: /tmp/pip-ephem-wheel-cache-_aazpdp6/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
      "2025-02-26T12:20:51: Successfully built deepspeed fusepy\n",
      "2025-02-26T12:20:52: Installing collected packages: sentencepiece, pytz, fusepy, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, applicationinsights, antlr4-python3-runtime, xxhash, wrapt, wheel, tzdata, typeguard, triton, tqdm, sympy, sqlparse, soupsieve, sniffio, smmap, shtab, setproctitle, sentry-sdk, safetensors, rpds-py, regex, python-dotenv, python-dateutil, PySocks, pygments, pyarrow, platformdirs, pkginfo, pathspec, packaging, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, msgpack, mdurl, Markdown, jsonpickle, jmespath, jiter, jeepney, isodate, importlib-resources, importlib-metadata, hf_transfer, h11, entrypoints, docstring-parser, docker-pycreds, distro, dill, contextlib2, cloudpickle, click, bcrypt, backports.tempfile, requests-oauthlib, referencing, pynacl, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, latex2sympy2_extended, knack, huggingface_hub, httpcore, gitdb, docker, deprecated, beautifulsoup4, anyio, tokenizers, SecretStorage, rich, pyopenssl, paramiko, opentelemetry-api, nvidia-cusolver-cu12, msrest, math_verify, jsonschema-specifications, httpx, gitpython, diffusers, databricks-sdk, azure-storage-blob, azure-mgmt-core, adal, wandb, tyro, transformers, torch, opentelemetry-semantic-conventions, openai, ndg-httpsclient, msrestazure, jsonschema, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, xformers, torchvision, opentelemetry-sdk, deepspeed, datasets, cut_cross_entropy, bitsandbytes, azureml-train-restclients-hyperdrive, azure-graphrbac, accelerate, trl, peft, mlflow_skinny, azureml-core, unsloth_zoo, azureml-telemetry, azureml-pipeline-core, azureml-mlflow, azureml-dataprep, unsloth, azureml-train-core, azureml-dataset-runtime, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n",
      "2025-02-26T12:20:53:   Attempting uninstall: wheel\n",
      "2025-02-26T12:20:53:     Found existing installation: wheel 0.41.2\n",
      "2025-02-26T12:20:53:     Uninstalling wheel-0.41.2:\n",
      "2025-02-26T12:20:53:       Successfully uninstalled wheel-0.41.2\n",
      "2025-02-26T12:20:53:   Attempting uninstall: triton\n",
      "2025-02-26T12:20:53:     Found existing installation: triton 3.0.0\n",
      "2025-02-26T12:20:53:     Uninstalling triton-3.0.0:\n",
      "2025-02-26T12:20:53:       Successfully uninstalled triton-3.0.0\n",
      "2025-02-26T12:20:56:   Attempting uninstall: tqdm\n",
      "2025-02-26T12:20:56:     Found existing installation: tqdm 4.66.5\n",
      "2025-02-26T12:20:56:     Uninstalling tqdm-4.66.5:\n",
      "2025-02-26T12:20:56:       Successfully uninstalled tqdm-4.66.5\n",
      "2025-02-26T12:20:56:   Attempting uninstall: sympy\n",
      "2025-02-26T12:20:56:     Found existing installation: sympy 1.13.3\n",
      "2025-02-26T12:20:56:     Uninstalling sympy-1.13.3:\n",
      "2025-02-26T12:20:56:       Successfully uninstalled sympy-1.13.3\n",
      "2025-02-26T12:21:26:   Attempting uninstall: packaging\n",
      "2025-02-26T12:21:26:     Found existing installation: packaging 24.1\n",
      "2025-02-26T12:21:26:     Uninstalling packaging-24.1:\n",
      "2025-02-26T12:21:26:       Successfully uninstalled packaging-24.1\n",
      "2025-02-26T12:21:37:   Attempting uninstall: numpy\n",
      "2025-02-26T12:21:37:     Found existing installation: numpy 1.24.4\n",
      "2025-02-26T12:21:37:     Uninstalling numpy-1.24.4:\n",
      "2025-02-26T12:21:37:       Successfully uninstalled numpy-1.24.4\n",
      "2025-02-26T12:21:39:   Attempting uninstall: importlib-metadata\n",
      "2025-02-26T12:21:39:     Found existing installation: importlib_metadata 8.5.0\n",
      "2025-02-26T12:21:39:     Uninstalling importlib_metadata-8.5.0:\n",
      "2025-02-26T12:21:39:       Successfully uninstalled importlib_metadata-8.5.0\n",
      "2025-02-26T12:22:28:   Attempting uninstall: torch\n",
      "2025-02-26T12:22:28:     Found existing installation: torch 2.4.1\n",
      "2025-02-26T12:22:28:     Uninstalling torch-2.4.1:\n",
      "2025-02-26T12:23:06:       Successfully uninstalled torch-2.4.1\n",
      "2025-02-26T12:23:44:   Attempting uninstall: torchvision\n",
      "2025-02-26T12:23:44:     Found existing installation: torchvision 0.19.1+cu124\n",
      "2025-02-26T12:23:44:     Uninstalling torchvision-0.19.1+cu124:\n",
      "2025-02-26T12:23:44:       Successfully uninstalled torchvision-0.19.1+cu124\n",
      "2025-02-26T12:23:44:   Attempting uninstall: deepspeed\n",
      "2025-02-26T12:23:44:     Found existing installation: deepspeed 0.15.1\n",
      "2025-02-26T12:23:44:     Uninstalling deepspeed-0.15.1:\n",
      "2025-02-26T12:23:45:       Successfully uninstalled deepspeed-0.15.1\n",
      "2025-02-26T12:23:53: \u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "2025-02-26T12:23:53: torchaudio 2.4.1+cu124 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\n",
      "2025-02-26T12:23:53: \u001b[0mSuccessfully installed Markdown-3.7 PySocks-1.7.1 SecretStorage-3.3.3 accelerate-1.4.0 adal-1.2.7 antlr4-python3-runtime-4.13.2 anyio-4.8.0 applicationinsights-0.11.10 azure-common-1.1.28 azure-graphrbac-0.61.2 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-10.3.0 azure-mgmt-core-1.5.0 azure-mgmt-keyvault-10.3.1 azure-mgmt-network-28.0.0 azure-mgmt-resource-23.3.0 azure-mgmt-storage-22.0.0 azure-storage-blob-12.19.0 azureml-automl-core-1.58.0 azureml-core-1.58.0.post1 azureml-dataprep-5.1.6 azureml-dataprep-native-41.0.0 azureml-dataprep-rslex-2.22.5 azureml-dataset-runtime-1.58.0 azureml-mlflow-1.58.0 azureml-pipeline-1.58.0 azureml-pipeline-core-1.58.0 azureml-pipeline-steps-1.58.0 azureml-sdk-1.58.0 azureml-telemetry-1.58.0 azureml-train-automl-client-1.58.0 azureml-train-core-1.58.0 azureml-train-restclients-hyperdrive-1.58.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.2.1 beautifulsoup4-4.13.3 bitsandbytes-0.45.3 click-8.1.8 cloudpickle-2.2.1 contextlib2-21.6.0 cut_cross_entropy-25.1.1 databricks-sdk-0.44.1 datasets-3.3.2 deepspeed-0.15.4 deprecated-1.2.18 diffusers-0.32.2 dill-0.3.8 distro-1.9.0 docker-7.1.0 docker-pycreds-0.4.0 docstring-parser-0.16 entrypoints-0.4 fusepy-3.0.1 gitdb-4.0.12 gitpython-3.1.44 h11-0.14.0 hf_transfer-0.1.9 httpcore-1.0.7 httpx-0.28.1 huggingface_hub-0.29.1 importlib-metadata-7.2.1 importlib-resources-6.4.0 isodate-0.7.2 jeepney-0.8.0 jiter-0.8.2 jmespath-1.0.1 jsonpickle-3.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 knack-0.12.0 latex2sympy2_extended-1.0.6 markdown-it-py-3.0.0 math_verify-0.5.2 mdurl-0.1.2 mlflow_skinny-2.15.0 msgpack-1.1.0 msrest-0.7.1 msrestazure-0.6.4.post1 multiprocess-0.70.16 ndg-httpsclient-0.5.1 numpy-1.23.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 oauthlib-3.2.2 openai-1.64.0 opentelemetry-api-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 packaging-24.2 pandas-2.2.3 paramiko-3.5.1 pathspec-0.12.1 peft-0.14.0 pkginfo-1.12.1.2 platformdirs-4.3.6 pyarrow-19.0.1 pygments-2.19.1 pynacl-1.5.0 pyopenssl-24.3.0 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 pytz-2024.2 referencing-0.36.2 regex-2024.11.6 requests-oauthlib-2.0.0 rich-13.9.4 rpds-py-0.23.1 safetensors-0.5.2 sentencepiece-0.2.0 sentry-sdk-2.22.0 setproctitle-1.3.5 shtab-1.7.1 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.6 sqlparse-0.5.3 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 torchvision-0.20.1 tqdm-4.66.4 transformers-4.48.2 triton-3.1.0 trl-0.15.1 typeguard-4.4.2 tyro-0.9.16 tzdata-2025.1 unsloth-2025.2.15 unsloth_zoo-2025.2.7 wandb-0.19.7 wheel-0.45.1 wrapt-1.17.2 xformers-0.0.29.post1 xxhash-3.5.0\n",
      "2025-02-26T12:23:53: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2025-02-26T12:25:44: \u001b[0mRemoving intermediate container ee5a5f0b726f\n",
      "2025-02-26T12:25:44:  ---> 97a57bf3ad99\n",
      "2025-02-26T12:25:44: Step 8/8 : Run pip install vllm\n",
      "2025-02-26T12:25:45:  ---> Running in d7fa3e83e2d4\n",
      "2025-02-26T12:25:46: Collecting vllm\n",
      "2025-02-26T12:25:46:   Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: psutil in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (6.1.0)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: sentencepiece in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (0.2.0)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: numpy<2.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (1.23.5)\n",
      "2025-02-26T12:25:46: Collecting numba==0.60.0 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: requests>=2.26.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (2.32.3)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: tqdm in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (4.66.4)\n",
      "2025-02-26T12:25:46: Collecting blake3 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: py-cpuinfo in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (9.0.0)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: transformers>=4.48.2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (4.48.2)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (0.21.0)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: protobuf in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (3.20.3)\n",
      "2025-02-26T12:25:46: Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:46:   Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: aiohttp in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (3.10.10)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: openai>=1.52.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (1.64.0)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: pydantic>=2.9 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (2.9.2)\n",
      "2025-02-26T12:25:46: Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: pillow in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (11.0.0)\n",
      "2025-02-26T12:25:46: Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:25:46: Collecting tiktoken>=0.6.0 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "2025-02-26T12:25:46: Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading lm_format_enforcer-0.10.10-py3-none-any.whl.metadata (17 kB)\n",
      "2025-02-26T12:25:46: Collecting outlines==0.1.11 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "2025-02-26T12:25:46: Collecting lark==1.2.2 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:25:46: Collecting xgrammar==0.1.11 (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: typing_extensions>=4.10 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (4.12.2)\n",
      "2025-02-26T12:25:46: Requirement already satisfied: filelock>=3.16.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (3.16.1)\n",
      "2025-02-26T12:25:46: Collecting partial-json-parser (from vllm)\n",
      "2025-02-26T12:25:46:   Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "2025-02-26T12:25:47: Collecting pyzmq (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading pyzmq-26.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
      "2025-02-26T12:25:47: Collecting msgspec (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "2025-02-26T12:25:47: Collecting gguf==0.10.0 (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: importlib_metadata in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (7.2.1)\n",
      "2025-02-26T12:25:47: Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm)\n",
      "2025-02-26T12:25:47:   Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: pyyaml in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (6.0.2)\n",
      "2025-02-26T12:25:47: Collecting einops (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-02-26T12:25:47: Collecting compressed-tensors==0.9.1 (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-02-26T12:25:47: Collecting depyf==0.18.0 (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: cloudpickle in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (2.2.1)\n",
      "2025-02-26T12:25:47: Collecting ray==2.40.0 (from ray[adag]==2.40.0->vllm)\n",
      "2025-02-26T12:25:47:   Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: torch==2.5.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (2.5.1)\n",
      "2025-02-26T12:25:47: Collecting torchaudio==2.5.1 (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: torchvision==0.20.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from vllm) (0.20.1)\n",
      "2025-02-26T12:25:47: Collecting xformers==0.0.28.post3 (from vllm)\n",
      "2025-02-26T12:25:47:   Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "2025-02-26T12:25:47: Collecting astor (from depyf==0.18.0->vllm)\n",
      "2025-02-26T12:25:47:   Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: dill in /opt/conda/envs/ptca/lib/python3.10/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "2025-02-26T12:25:47: Collecting llvmlite<0.44,>=0.43.0dev0 (from numba==0.60.0->vllm)\n",
      "2025-02-26T12:25:47:   Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "2025-02-26T12:25:47: Collecting interegular (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:47:   Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: jinja2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (3.1.4)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: nest_asyncio in /opt/conda/envs/ptca/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "2025-02-26T12:25:47: Collecting diskcache (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:47:   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: referencing in /opt/conda/envs/ptca/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "2025-02-26T12:25:47: Requirement already satisfied: jsonschema in /opt/conda/envs/ptca/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "2025-02-26T12:25:47: Collecting pycountry (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:47:   Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "2025-02-26T12:25:47: Collecting airportsdata (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:47:   Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
      "2025-02-26T12:25:48: Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:48:   Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: click>=7.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (8.1.8)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.1.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: packaging in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (24.2)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: aiosignal in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.3.1)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: frozenlist in /opt/conda/envs/ptca/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.5.0)\n",
      "2025-02-26T12:25:48: Collecting cupy-cuda12x (from ray[adag]==2.40.0->vllm)\n",
      "2025-02-26T12:25:48:   Downloading cupy_cuda12x-13.3.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: networkx in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (3.4.2)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: fsspec in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (2024.10.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (2.21.5)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: triton==3.1.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (3.1.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: sympy==1.13.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from torch==2.5.1->vllm) (1.13.1)\n",
      "2025-02-26T12:25:48: Collecting pybind11 (from xgrammar==0.1.11->vllm)\n",
      "2025-02-26T12:25:48:   Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: pytest in /opt/conda/envs/ptca/lib/python3.10/site-packages (from xgrammar==0.1.11->vllm) (7.4.3)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
      "2025-02-26T12:25:48: Collecting starlette<0.46.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:48:   Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "2025-02-26T12:25:48: Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:48:   Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: httpx>=0.23.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.28.1)\n",
      "2025-02-26T12:25:48: Collecting jinja2 (from outlines==0.1.11->vllm)\n",
      "2025-02-26T12:25:48:   Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-02-26T12:25:48: Collecting python-multipart>=0.0.18 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:48:   Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "2025-02-26T12:25:48: Collecting email-validator>=2.0.0 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:48:   Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "2025-02-26T12:25:48: Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:48:   Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "2025-02-26T12:25:48: Collecting numpy<2.0.0 (from vllm)\n",
      "2025-02-26T12:25:48:   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-02-26T12:25:48: Collecting opencv-python-headless>=4.0.0 (from mistral_common[opencv]>=1.5.0->vllm)\n",
      "2025-02-26T12:25:48:   Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (4.8.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: sniffio in /opt/conda/envs/ptca/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pydantic>=2.9->vllm) (2.23.4)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (3.4.0)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (2.2.3)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (2024.8.30)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: regex>=2022.1.18 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
      "2025-02-26T12:25:48: Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm) (0.29.1)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->vllm) (2.4.3)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->vllm) (24.2.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->vllm) (6.1.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->vllm) (1.16.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from aiohttp->vllm) (4.0.3)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from importlib_metadata->vllm) (3.20.2)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm) (1.2.2)\n",
      "2025-02-26T12:25:49: Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "2025-02-26T12:25:49: Collecting typer>=0.12.3 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "2025-02-26T12:25:49: Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: httpcore==1.* in /opt/conda/envs/ptca/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (1.0.7)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.14.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.23.1)\n",
      "2025-02-26T12:25:49: Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (1.0.1)\n",
      "2025-02-26T12:25:49: Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-02-26T12:25:49: Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-02-26T12:25:49: Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading websockets-15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->vllm) (0.2.0)\n",
      "2025-02-26T12:25:49: Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[adag]==2.40.0->vllm)\n",
      "2025-02-26T12:25:49:   Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: iniconfig in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pytest->xgrammar==0.1.11->vllm) (2.0.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pytest->xgrammar==0.1.11->vllm) (1.5.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: tomli>=1.0.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from pytest->xgrammar==0.1.11->vllm) (2.0.2)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: rich>=13.7.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (13.9.4)\n",
      "2025-02-26T12:25:49: Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "2025-02-26T12:25:49:   Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (3.0.0)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (2.19.1)\n",
      "2025-02-26T12:25:49: Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/ptca/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.1.2)\n",
      "2025-02-26T12:25:49: Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
      "2025-02-26T12:25:53:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 264.6/264.6 MB 86.4 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:53: Downloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
      "2025-02-26T12:25:53: Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "2025-02-26T12:25:53: Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "2025-02-26T12:25:53: Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "2025-02-26T12:25:53: Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "2025-02-26T12:25:53:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 87.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:53: Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "2025-02-26T12:25:53: Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.8/66.8 MB 67.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 81.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.7/16.7 MB 107.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "2025-02-26T12:25:54: Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "2025-02-26T12:25:54: Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "2025-02-26T12:25:54: Downloading lm_format_enforcer-0.10.10-py3-none-any.whl (44 kB)\n",
      "2025-02-26T12:25:54: Downloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 81.0 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 74.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "2025-02-26T12:25:54: Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
      "2025-02-26T12:25:54: Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 40.8 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
      "2025-02-26T12:25:54: Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "2025-02-26T12:25:54: Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "2025-02-26T12:25:54: Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "2025-02-26T12:25:54: Downloading pyzmq-26.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (874 kB)\n",
      "2025-02-26T12:25:54:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 874.2/874.2 kB 34.5 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:54: Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "2025-02-26T12:25:54: Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
      "2025-02-26T12:25:54: Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "2025-02-26T12:25:54: Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "2025-02-26T12:25:55: Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "2025-02-26T12:25:55:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 69.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:55: Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "2025-02-26T12:25:56:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.0/50.0 MB 75.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:56: Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "2025-02-26T12:25:56: Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "2025-02-26T12:25:56: Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "2025-02-26T12:25:56: Downloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
      "2025-02-26T12:25:56:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 913.7/913.7 kB 36.1 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:56: Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "2025-02-26T12:25:56: Downloading cupy_cuda12x-13.3.0-cp310-cp310-manylinux2014_x86_64.whl (90.6 MB)\n",
      "2025-02-26T12:25:57:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 MB 69.6 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:57: Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "2025-02-26T12:25:57: Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "2025-02-26T12:25:57: Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "2025-02-26T12:25:57:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 99.0 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:57: Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "2025-02-26T12:25:57: Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "2025-02-26T12:25:57: Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "2025-02-26T12:25:57: Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
      "2025-02-26T12:25:57: Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "2025-02-26T12:25:57: Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "2025-02-26T12:25:57:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 80.3 MB/s eta 0:00:00\n",
      "2025-02-26T12:25:57: Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "2025-02-26T12:25:57: Downloading websockets-15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (180 kB)\n",
      "2025-02-26T12:25:57: Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "2025-02-26T12:26:00: Installing collected packages: fastrlock, blake3, websockets, uvloop, uvicorn, shellingham, pyzmq, python-multipart, pycountry, pybind11, prometheus_client, partial-json-parser, numpy, msgspec, llvmlite, lark, jinja2, interegular, httptools, einops, dnspython, diskcache, astor, airportsdata, watchfiles, tiktoken, starlette, opencv-python-headless, numba, gguf, email-validator, depyf, cupy-cuda12x, typer, rich-toolkit, prometheus-fastapi-instrumentator, lm-format-enforcer, fastapi, xformers, torchaudio, ray, outlines_core, mistral_common, fastapi-cli, xgrammar, outlines, compressed-tensors, vllm\n",
      "2025-02-26T12:26:01:   Attempting uninstall: numpy\n",
      "2025-02-26T12:26:01:     Found existing installation: numpy 1.23.5\n",
      "2025-02-26T12:26:01:     Uninstalling numpy-1.23.5:\n",
      "2025-02-26T12:26:01:       Successfully uninstalled numpy-1.23.5\n",
      "2025-02-26T12:26:03:   Attempting uninstall: jinja2\n",
      "2025-02-26T12:26:03:     Found existing installation: Jinja2 3.1.4\n",
      "2025-02-26T12:26:03:     Uninstalling Jinja2-3.1.4:\n",
      "2025-02-26T12:26:03:       Successfully uninstalled Jinja2-3.1.4\n",
      "2025-02-26T12:26:09:   Attempting uninstall: xformers\n",
      "2025-02-26T12:26:09:     Found existing installation: xformers 0.0.29.post1\n",
      "2025-02-26T12:26:09:     Uninstalling xformers-0.0.29.post1:\n",
      "2025-02-26T12:26:09:       Successfully uninstalled xformers-0.0.29.post1\n",
      "2025-02-26T12:26:09:   Attempting uninstall: torchaudio\n",
      "2025-02-26T12:26:09:     Found existing installation: torchaudio 2.4.1+cu124\n",
      "2025-02-26T12:26:09:     Uninstalling torchaudio-2.4.1+cu124:\n",
      "2025-02-26T12:26:09:       Successfully uninstalled torchaudio-2.4.1+cu124\n",
      "2025-02-26T12:26:19: \u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "2025-02-26T12:26:19: azureml-dataset-runtime 1.58.0 requires numpy!=1.19.3,<1.24; sys_platform == \"linux\", but you have numpy 1.26.4 which is incompatible.\n",
      "2025-02-26T12:26:19: \u001b[0mSuccessfully installed airportsdata-20250224 astor-0.8.1 blake3-1.0.4 compressed-tensors-0.9.1 cupy-cuda12x-13.3.0 depyf-0.18.0 diskcache-5.6.3 dnspython-2.7.0 einops-0.8.1 email-validator-2.2.0 fastapi-0.115.8 fastapi-cli-0.0.7 fastrlock-0.8.3 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 jinja2-3.1.5 lark-1.2.2 llvmlite-0.43.0 lm-format-enforcer-0.10.10 mistral_common-1.5.3 msgspec-0.19.0 numba-0.60.0 numpy-1.26.4 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.0.2 prometheus_client-0.21.1 pybind11-2.13.6 pycountry-24.6.1 python-multipart-0.0.20 pyzmq-26.2.1 ray-2.40.0 rich-toolkit-0.13.2 shellingham-1.5.4 starlette-0.45.3 tiktoken-0.9.0 torchaudio-2.5.1 typer-0.15.1 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.7.3 watchfiles-1.0.4 websockets-15.0 xformers-0.0.28.post3 xgrammar-0.1.11\n",
      "2025-02-26T12:26:19: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2025-02-26T12:27:19: \u001b[0mRemoving intermediate container d7fa3e83e2d4\n",
      "2025-02-26T12:27:19:  ---> 619a2e05907a\n",
      "2025-02-26T12:27:19: Successfully built 619a2e05907a\n",
      "2025-02-26T12:27:19: Successfully tagged f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415:latest\n",
      "2025-02-26T12:27:19: Successfully tagged f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415:1\n",
      "\n",
      "\n",
      "2025-02-26T12:27:19: Logging into Docker registry: f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io\n",
      "2025-02-26T12:27:19: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-02-26T12:27:20: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "2025-02-26T12:27:20: Configure a credential helper to remove this warning. See\n",
      "2025-02-26T12:27:20: https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "2025-02-26T12:27:20: Login Succeeded\n",
      "\n",
      "\n",
      "2025-02-26T12:27:20: #### send_dependencies.py not found in current directory or its subdirectories.\n",
      "2025-02-26T12:27:20: Using default tag: latest\n",
      "2025-02-26T12:27:20: The push refers to repository [f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415]\n",
      "2025-02-26T12:27:20: 91546dbdc6dd: Preparing\n",
      "2025-02-26T12:27:20: 3792b3bbd6a3: Preparing\n",
      "2025-02-26T12:27:20: 6f94941859c7: Preparing\n",
      "2025-02-26T12:27:20: cb42adc5f10e: Preparing\n",
      "2025-02-26T12:27:20: ba6cce9d0be6: Preparing\n",
      "2025-02-26T12:27:20: 27bc696bf5f5: Preparing\n",
      "2025-02-26T12:27:20: 991a1377a367: Preparing\n",
      "2025-02-26T12:27:20: b88999fa2f48: Preparing\n",
      "2025-02-26T12:27:20: c04cf9891581: Preparing\n",
      "2025-02-26T12:27:20: f62178edb7e8: Preparing\n",
      "2025-02-26T12:27:20: 5609d1a95327: Preparing\n",
      "2025-02-26T12:27:20: 9461422de5d6: Preparing\n",
      "2025-02-26T12:27:20: 4736a8d58e55: Preparing\n",
      "2025-02-26T12:27:20: db7df9cb52cf: Preparing\n",
      "2025-02-26T12:27:20: 949b1d7e2196: Preparing\n",
      "2025-02-26T12:27:20: 38e96d087c79: Preparing\n",
      "2025-02-26T12:27:20: 9232fa8dac86: Preparing\n",
      "2025-02-26T12:27:20: 5a0a2540dd38: Preparing\n",
      "2025-02-26T12:27:20: e182807adf59: Preparing\n",
      "2025-02-26T12:27:20: 8182421d54e8: Preparing\n",
      "2025-02-26T12:27:20: f8f6b47a51b5: Preparing\n",
      "2025-02-26T12:27:20: 3eee0573828e: Preparing\n",
      "2025-02-26T12:27:20: 274e4d04dbce: Preparing\n",
      "2025-02-26T12:27:20: 757fd34b891b: Preparing\n",
      "2025-02-26T12:27:20: 27bc696bf5f5: Waiting\n",
      "2025-02-26T12:27:20: 99e6b5183855: Preparing\n",
      "2025-02-26T12:27:20: 991a1377a367: Waiting\n",
      "2025-02-26T12:27:20: b88999fa2f48: Waiting\n",
      "2025-02-26T12:27:20: c04cf9891581: Waiting\n",
      "2025-02-26T12:27:20: f62178edb7e8: Waiting\n",
      "2025-02-26T12:27:20: dc206f61230e: Preparing\n",
      "2025-02-26T12:27:20: 5609d1a95327: Waiting\n",
      "2025-02-26T12:27:20: 6b6449cbddd8: Preparing\n",
      "2025-02-26T12:27:20: 9461422de5d6: Waiting\n",
      "2025-02-26T12:27:20: 4736a8d58e55: Waiting\n",
      "2025-02-26T12:27:20: f7896ea0d0b5: Preparing\n",
      "2025-02-26T12:27:20: db7df9cb52cf: Waiting\n",
      "2025-02-26T12:27:20: 9e115168f6c8: Preparing\n",
      "2025-02-26T12:27:20: 949b1d7e2196: Waiting\n",
      "2025-02-26T12:27:20: c787cec5c863: Preparing\n",
      "2025-02-26T12:27:20: 38e96d087c79: Waiting\n",
      "2025-02-26T12:27:20: 3eee0573828e: Waiting\n",
      "2025-02-26T12:27:20: 274e4d04dbce: Waiting\n",
      "2025-02-26T12:27:20: 757fd34b891b: Waiting\n",
      "2025-02-26T12:27:20: 99e6b5183855: Waiting\n",
      "2025-02-26T12:27:20: 9232fa8dac86: Waiting\n",
      "2025-02-26T12:27:20: 5a0a2540dd38: Waiting\n",
      "2025-02-26T12:27:20: dc206f61230e: Waiting\n",
      "2025-02-26T12:27:20: 6b6449cbddd8: Waiting\n",
      "2025-02-26T12:27:20: f7896ea0d0b5: Waiting\n",
      "2025-02-26T12:27:20: e182807adf59: Waiting\n",
      "2025-02-26T12:27:20: 8182421d54e8: Waiting\n",
      "2025-02-26T12:27:20: f8f6b47a51b5: Waiting\n",
      "2025-02-26T12:27:20: 9e115168f6c8: Waiting\n",
      "2025-02-26T12:27:20: 8f5780bbdbcd: Preparing\n",
      "2025-02-26T12:27:20: 411ddc4c5fa9: Preparing\n",
      "2025-02-26T12:27:20: 4c661a573238: Preparing\n",
      "2025-02-26T12:27:20: 3d2a8f8fcc26: Preparing\n",
      "2025-02-26T12:27:20: 9f3ac9ad3cd3: Preparing\n",
      "2025-02-26T12:27:20: 76e4ac1907ba: Preparing\n",
      "2025-02-26T12:27:20: e8251e8eabd6: Preparing\n",
      "2025-02-26T12:27:20: b262c6329a45: Preparing\n",
      "2025-02-26T12:27:20: 78011e011ca1: Preparing\n",
      "2025-02-26T12:27:20: 882acb3fbb9d: Preparing\n",
      "2025-02-26T12:27:20: 9375032f1539: Preparing\n",
      "2025-02-26T12:27:20: ccf17877232e: Preparing\n",
      "2025-02-26T12:27:20: bed3270bc1c6: Preparing\n",
      "2025-02-26T12:27:20: 809d3bb9c80f: Preparing\n",
      "2025-02-26T12:27:20: 5136ffc45974: Preparing\n",
      "2025-02-26T12:27:20: 2ecbf7829cb7: Preparing\n",
      "2025-02-26T12:27:20: cd76869b72ab: Preparing\n",
      "2025-02-26T12:27:20: 106e8431b412: Preparing\n",
      "2025-02-26T12:27:20: c787cec5c863: Waiting\n",
      "2025-02-26T12:27:20: 8f5780bbdbcd: Waiting\n",
      "2025-02-26T12:27:20: 411ddc4c5fa9: Waiting\n",
      "2025-02-26T12:27:20: 4c661a573238: Waiting\n",
      "2025-02-26T12:27:20: ccf17877232e: Waiting\n",
      "2025-02-26T12:27:20: 3d2a8f8fcc26: Waiting\n",
      "2025-02-26T12:27:20: bed3270bc1c6: Waiting\n",
      "2025-02-26T12:27:20: 9f3ac9ad3cd3: Waiting\n",
      "2025-02-26T12:27:20: cd76869b72ab: Waiting\n",
      "2025-02-26T12:27:20: 76e4ac1907ba: Waiting\n",
      "2025-02-26T12:27:20: 809d3bb9c80f: Waiting\n",
      "2025-02-26T12:27:20: 106e8431b412: Waiting\n",
      "2025-02-26T12:27:20: e8251e8eabd6: Waiting\n",
      "2025-02-26T12:27:20: 5136ffc45974: Waiting\n",
      "2025-02-26T12:27:20: b262c6329a45: Waiting\n",
      "2025-02-26T12:27:20: 2ecbf7829cb7: Waiting\n",
      "2025-02-26T12:27:20: 9375032f1539: Waiting\n",
      "2025-02-26T12:27:20: 78011e011ca1: Waiting\n",
      "2025-02-26T12:27:20: 882acb3fbb9d: Waiting\n",
      "2025-02-26T12:27:20: 6f94941859c7: Pushed\n",
      "2025-02-26T12:27:21: ba6cce9d0be6: Pushed\n",
      "2025-02-26T12:27:21: 991a1377a367: Pushed\n",
      "2025-02-26T12:27:22: cb42adc5f10e: Pushed\n",
      "2025-02-26T12:27:22: b88999fa2f48: Pushed\n",
      "2025-02-26T12:27:22: c04cf9891581: Pushed\n",
      "2025-02-26T12:27:22: f62178edb7e8: Pushed\n",
      "2025-02-26T12:27:22: 5609d1a95327: Pushed\n",
      "2025-02-26T12:27:22: 9461422de5d6: Pushed\n",
      "2025-02-26T12:27:23: 4736a8d58e55: Pushed\n",
      "2025-02-26T12:27:23: 949b1d7e2196: Pushed\n",
      "2025-02-26T12:27:23: db7df9cb52cf: Pushed\n",
      "2025-02-26T12:27:23: 9232fa8dac86: Pushed\n",
      "2025-02-26T12:27:24: 38e96d087c79: Pushed\n",
      "2025-02-26T12:27:24: 5a0a2540dd38: Pushed\n",
      "2025-02-26T12:27:24: e182807adf59: Pushed\n",
      "2025-02-26T12:27:24: f8f6b47a51b5: Pushed\n",
      "2025-02-26T12:27:25: 3eee0573828e: Pushed\n",
      "2025-02-26T12:27:27: 8182421d54e8: Pushed\n",
      "2025-02-26T12:27:28: 757fd34b891b: Pushed\n",
      "2025-02-26T12:27:31: 27bc696bf5f5: Pushed\n",
      "2025-02-26T12:27:32: dc206f61230e: Pushed\n",
      "2025-02-26T12:27:33: 6b6449cbddd8: Pushed\n",
      "2025-02-26T12:27:59: f7896ea0d0b5: Pushed\n",
      "2025-02-26T12:27:59: 9e115168f6c8: Pushed\n",
      "2025-02-26T12:28:29: c787cec5c863: Pushed\n",
      "2025-02-26T12:29:32: 99e6b5183855: Pushed\n",
      "2025-02-26T12:29:33: 411ddc4c5fa9: Pushed\n",
      "2025-02-26T12:29:36: 8f5780bbdbcd: Pushed\n",
      "2025-02-26T12:29:37: 3d2a8f8fcc26: Pushed\n",
      "2025-02-26T12:29:38: 9f3ac9ad3cd3: Pushed\n",
      "2025-02-26T12:29:55: 76e4ac1907ba: Pushed\n",
      "2025-02-26T12:29:56: e8251e8eabd6: Pushed\n",
      "2025-02-26T12:29:56: b262c6329a45: Pushed\n",
      "2025-02-26T12:30:00: 91546dbdc6dd: Pushed\n",
      "2025-02-26T12:30:01: 882acb3fbb9d: Pushed\n",
      "2025-02-26T12:30:01: 9375032f1539: Pushed\n",
      "2025-02-26T12:30:02: ccf17877232e: Pushed\n",
      "2025-02-26T12:30:27: 4c661a573238: Pushed\n",
      "2025-02-26T12:30:28: 809d3bb9c80f: Pushed\n",
      "2025-02-26T12:30:28: 5136ffc45974: Pushed\n",
      "2025-02-26T12:30:41: 2ecbf7829cb7: Pushed\n",
      "2025-02-26T12:30:43: cd76869b72ab: Pushed\n",
      "2025-02-26T12:30:54: 106e8431b412: Pushed\n",
      "2025-02-26T12:32:04: bed3270bc1c6: Pushed\n",
      "2025-02-26T12:33:31: 3792b3bbd6a3: Pushed\n",
      "2025-02-26T12:34:04: 78011e011ca1: Pushed\n",
      "2025-02-26T12:34:10: 274e4d04dbce: Pushed\n",
      "2025-02-26T12:34:11: latest: digest: sha256:a2ca35947eac6afd2cc546dd98c086c669849f2d7db6c4dd1a64ca6809705b49 size: 10391\n",
      "\n",
      "\n",
      "2025-02-26T12:34:11: #### Image digest: sha256:a2ca35947eac6afd2cc546dd98c086c669849f2d7db6c4dd1a64ca6809705b49\n",
      "2025-02-26T12:34:11: #### Calling generate_sbom\n",
      "2025-02-26T12:34:11: #### Generating SBOM \n",
      "2025-02-26T12:34:11: #### Running command: trivy image --no-progress --format spdx-json --skip-db-update --skip-java-db-update --offline-scan --output image-details.json f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415 --timeout 10m0s\n",
      "2025-02-26T12:34:12Z\tINFO\t\"--format spdx\" and \"--format spdx-json\" disable security scanning\n",
      "2025-02-26T12:44:05Z\tERROR\tThe first run cannot skip downloading Java DB\n",
      "2025-02-26T12:44:08Z\tFATAL\tFatal error\timage scan error: scan error: scan failed: failed analysis: analyze error: pipeline error: failed to analyze layer (sha256:4c661a5732389391d1b4cf501d262b8871f2954ac2b8a4def78a13b87f28b490): post analysis error: post analysis error: Unable to initialize the Java DB: Java DB update failed: '--skip-java-db-update' cannot be specified on the first run\n",
      "2025-02-26T12:44:08: Call failed with error:\n",
      "\n",
      "2025-02-26T12:44:08: #### Exception encountered when generating sbom: Command '['trivy', 'image', '--no-progress', '--format', 'spdx-json', '--skip-db-update', '--skip-java-db-update', '--offline-scan', '--output', 'image-details.json', 'f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415', '--timeout', '10m0s']' returned non-zero exit status 1.\n",
      "2025-02-26T12:44:08: The push refers to repository [f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415]\n",
      "2025-02-26T12:44:08: 91546dbdc6dd: Preparing\n",
      "2025-02-26T12:44:08: 3792b3bbd6a3: Preparing\n",
      "2025-02-26T12:44:08: 6f94941859c7: Preparing\n",
      "2025-02-26T12:44:08: cb42adc5f10e: Preparing\n",
      "2025-02-26T12:44:08: ba6cce9d0be6: Preparing\n",
      "2025-02-26T12:44:08: 27bc696bf5f5: Preparing\n",
      "2025-02-26T12:44:08: 991a1377a367: Preparing\n",
      "2025-02-26T12:44:08: b88999fa2f48: Preparing\n",
      "2025-02-26T12:44:08: c04cf9891581: Preparing\n",
      "2025-02-26T12:44:08: f62178edb7e8: Preparing\n",
      "2025-02-26T12:44:08: 5609d1a95327: Preparing\n",
      "2025-02-26T12:44:08: 9461422de5d6: Preparing\n",
      "2025-02-26T12:44:08: 4736a8d58e55: Preparing\n",
      "2025-02-26T12:44:08: db7df9cb52cf: Preparing\n",
      "2025-02-26T12:44:08: 949b1d7e2196: Preparing\n",
      "2025-02-26T12:44:08: 38e96d087c79: Preparing\n",
      "2025-02-26T12:44:08: 9232fa8dac86: Preparing\n",
      "2025-02-26T12:44:08: 5a0a2540dd38: Preparing\n",
      "2025-02-26T12:44:08: e182807adf59: Preparing\n",
      "2025-02-26T12:44:08: 8182421d54e8: Preparing\n",
      "2025-02-26T12:44:08: f8f6b47a51b5: Preparing\n",
      "2025-02-26T12:44:08: 3eee0573828e: Preparing\n",
      "2025-02-26T12:44:08: 274e4d04dbce: Preparing\n",
      "2025-02-26T12:44:08: 757fd34b891b: Preparing\n",
      "2025-02-26T12:44:08: 99e6b5183855: Preparing\n",
      "2025-02-26T12:44:08: dc206f61230e: Preparing\n",
      "2025-02-26T12:44:08: 6b6449cbddd8: Preparing\n",
      "2025-02-26T12:44:08: f7896ea0d0b5: Preparing\n",
      "2025-02-26T12:44:08: 9e115168f6c8: Preparing\n",
      "2025-02-26T12:44:08: c787cec5c863: Preparing\n",
      "2025-02-26T12:44:08: 8f5780bbdbcd: Preparing\n",
      "2025-02-26T12:44:08: 411ddc4c5fa9: Preparing\n",
      "2025-02-26T12:44:08: 4c661a573238: Preparing\n",
      "2025-02-26T12:44:08: 3d2a8f8fcc26: Preparing\n",
      "2025-02-26T12:44:08: 9f3ac9ad3cd3: Preparing\n",
      "2025-02-26T12:44:08: 76e4ac1907ba: Preparing\n",
      "2025-02-26T12:44:08: e8251e8eabd6: Preparing\n",
      "2025-02-26T12:44:08: b262c6329a45: Preparing\n",
      "2025-02-26T12:44:08: 78011e011ca1: Preparing\n",
      "2025-02-26T12:44:08: 882acb3fbb9d: Preparing\n",
      "2025-02-26T12:44:08: 9375032f1539: Preparing\n",
      "2025-02-26T12:44:08: ccf17877232e: Preparing\n",
      "2025-02-26T12:44:08: bed3270bc1c6: Preparing\n",
      "2025-02-26T12:44:08: 809d3bb9c80f: Preparing\n",
      "2025-02-26T12:44:08: 5136ffc45974: Preparing\n",
      "2025-02-26T12:44:08: 2ecbf7829cb7: Preparing\n",
      "2025-02-26T12:44:08: cd76869b72ab: Preparing\n",
      "2025-02-26T12:44:08: 106e8431b412: Preparing\n",
      "2025-02-26T12:44:08: 27bc696bf5f5: Waiting\n",
      "2025-02-26T12:44:08: 991a1377a367: Waiting\n",
      "2025-02-26T12:44:08: b88999fa2f48: Waiting\n",
      "2025-02-26T12:44:08: 9e115168f6c8: Waiting\n",
      "2025-02-26T12:44:08: c04cf9891581: Waiting\n",
      "2025-02-26T12:44:08: c787cec5c863: Waiting\n",
      "2025-02-26T12:44:08: f62178edb7e8: Waiting\n",
      "2025-02-26T12:44:08: 8f5780bbdbcd: Waiting\n",
      "2025-02-26T12:44:08: 5609d1a95327: Waiting\n",
      "2025-02-26T12:44:08: 411ddc4c5fa9: Waiting\n",
      "2025-02-26T12:44:08: 4c661a573238: Waiting\n",
      "2025-02-26T12:44:08: 9232fa8dac86: Waiting\n",
      "2025-02-26T12:44:08: 5a0a2540dd38: Waiting\n",
      "2025-02-26T12:44:08: e182807adf59: Waiting\n",
      "2025-02-26T12:44:08: 8182421d54e8: Waiting\n",
      "2025-02-26T12:44:08: 4736a8d58e55: Waiting\n",
      "2025-02-26T12:44:08: f8f6b47a51b5: Waiting\n",
      "2025-02-26T12:44:08: db7df9cb52cf: Waiting\n",
      "2025-02-26T12:44:08: dc206f61230e: Waiting\n",
      "2025-02-26T12:44:08: 3eee0573828e: Waiting\n",
      "2025-02-26T12:44:08: 274e4d04dbce: Waiting\n",
      "2025-02-26T12:44:08: 6b6449cbddd8: Waiting\n",
      "2025-02-26T12:44:08: 949b1d7e2196: Waiting\n",
      "2025-02-26T12:44:08: 38e96d087c79: Waiting\n",
      "2025-02-26T12:44:08: 757fd34b891b: Waiting\n",
      "2025-02-26T12:44:08: 99e6b5183855: Waiting\n",
      "2025-02-26T12:44:08: bed3270bc1c6: Waiting\n",
      "2025-02-26T12:44:08: 809d3bb9c80f: Waiting\n",
      "2025-02-26T12:44:08: 5136ffc45974: Waiting\n",
      "2025-02-26T12:44:08: 2ecbf7829cb7: Waiting\n",
      "2025-02-26T12:44:08: cd76869b72ab: Waiting\n",
      "2025-02-26T12:44:08: 9f3ac9ad3cd3: Waiting\n",
      "2025-02-26T12:44:08: 78011e011ca1: Waiting\n",
      "2025-02-26T12:44:08: 76e4ac1907ba: Waiting\n",
      "2025-02-26T12:44:08: 882acb3fbb9d: Waiting\n",
      "2025-02-26T12:44:08: e8251e8eabd6: Waiting\n",
      "2025-02-26T12:44:08: b262c6329a45: Waiting\n",
      "2025-02-26T12:44:08: 106e8431b412: Waiting\n",
      "2025-02-26T12:44:08: 9375032f1539: Waiting\n",
      "2025-02-26T12:44:08: ccf17877232e: Waiting\n",
      "2025-02-26T12:44:08: 3792b3bbd6a3: Layer already exists\n",
      "2025-02-26T12:44:08: cb42adc5f10e: Layer already exists\n",
      "2025-02-26T12:44:08: 6f94941859c7: Layer already exists\n",
      "2025-02-26T12:44:08: 91546dbdc6dd: Layer already exists\n",
      "2025-02-26T12:44:08: ba6cce9d0be6: Layer already exists\n",
      "2025-02-26T12:44:08: f62178edb7e8: Layer already exists\n",
      "2025-02-26T12:44:08: b88999fa2f48: Layer already exists\n",
      "2025-02-26T12:44:08: c04cf9891581: Layer already exists\n",
      "2025-02-26T12:44:08: 991a1377a367: Layer already exists\n",
      "2025-02-26T12:44:08: 27bc696bf5f5: Layer already exists\n",
      "2025-02-26T12:44:08: 5609d1a95327: Layer already exists\n",
      "2025-02-26T12:44:08: 949b1d7e2196: Layer already exists\n",
      "2025-02-26T12:44:08: 4736a8d58e55: Layer already exists\n",
      "2025-02-26T12:44:08: 9461422de5d6: Layer already exists\n",
      "2025-02-26T12:44:08: db7df9cb52cf: Layer already exists\n",
      "2025-02-26T12:44:08: 38e96d087c79: Layer already exists\n",
      "2025-02-26T12:44:08: 5a0a2540dd38: Layer already exists\n",
      "2025-02-26T12:44:08: 9232fa8dac86: Layer already exists\n",
      "2025-02-26T12:44:08: e182807adf59: Layer already exists\n",
      "2025-02-26T12:44:09: f8f6b47a51b5: Layer already exists\n",
      "2025-02-26T12:44:09: 274e4d04dbce: Layer already exists\n",
      "2025-02-26T12:44:09: 8182421d54e8: Layer already exists\n",
      "2025-02-26T12:44:09: 3eee0573828e: Layer already exists\n",
      "2025-02-26T12:44:09: 757fd34b891b: Layer already exists\n",
      "2025-02-26T12:44:09: dc206f61230e: Layer already exists\n",
      "2025-02-26T12:44:09: 6b6449cbddd8: Layer already exists\n",
      "2025-02-26T12:44:09: 99e6b5183855: Layer already exists\n",
      "2025-02-26T12:44:09: 9e115168f6c8: Layer already exists\n",
      "2025-02-26T12:44:09: f7896ea0d0b5: Layer already exists\n",
      "2025-02-26T12:44:09: 8f5780bbdbcd: Layer already exists\n",
      "2025-02-26T12:44:09: 4c661a573238: Layer already exists\n",
      "2025-02-26T12:44:09: 411ddc4c5fa9: Layer already exists\n",
      "2025-02-26T12:44:09: c787cec5c863: Layer already exists\n",
      "2025-02-26T12:44:09: 3d2a8f8fcc26: Layer already exists\n",
      "2025-02-26T12:44:09: 76e4ac1907ba: Layer already exists\n",
      "2025-02-26T12:44:09: 9f3ac9ad3cd3: Layer already exists\n",
      "2025-02-26T12:44:09: b262c6329a45: Layer already exists\n",
      "2025-02-26T12:44:09: 78011e011ca1: Layer already exists\n",
      "2025-02-26T12:44:09: 882acb3fbb9d: Layer already exists\n",
      "2025-02-26T12:44:09: e8251e8eabd6: Layer already exists\n",
      "2025-02-26T12:44:09: 9375032f1539: Layer already exists\n",
      "2025-02-26T12:44:09: bed3270bc1c6: Layer already exists\n",
      "2025-02-26T12:44:09: 5136ffc45974: Layer already exists\n",
      "2025-02-26T12:44:09: ccf17877232e: Layer already exists\n",
      "2025-02-26T12:44:09: 809d3bb9c80f: Layer already exists\n",
      "2025-02-26T12:44:09: 2ecbf7829cb7: Layer already exists\n",
      "2025-02-26T12:44:09: cd76869b72ab: Layer already exists\n",
      "2025-02-26T12:44:09: 106e8431b412: Layer already exists\n",
      "2025-02-26T12:44:09: 1: digest: sha256:a2ca35947eac6afd2cc546dd98c086c669849f2d7db6c4dd1a64ca6809705b49 size: 10391\n",
      "\n",
      "\n",
      "2025-02-26T12:44:10: #### Image digest: sha256:a2ca35947eac6afd2cc546dd98c086c669849f2d7db6c4dd1a64ca6809705b49\n",
      "2025-02-26T12:44:10: #### Calling generate_sbom\n",
      "2025-02-26T12:44:10: #### Generating SBOM \n",
      "2025-02-26T12:44:10: #### Running command: trivy image --no-progress --format spdx-json --skip-db-update --skip-java-db-update --offline-scan --output image-details.json f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415:1 --timeout 10m0s\n",
      "2025-02-26T12:44:10Z\tINFO\t\"--format spdx\" and \"--format spdx-json\" disable security scanning\n",
      "2025-02-26T12:53:13Z\tERROR\tThe first run cannot skip downloading Java DB\n",
      "2025-02-26T12:53:17Z\tFATAL\tFatal error\timage scan error: scan error: scan failed: failed analysis: analyze error: pipeline error: failed to analyze layer (sha256:4c661a5732389391d1b4cf501d262b8871f2954ac2b8a4def78a13b87f28b490): post analysis error: post analysis error: Unable to initialize the Java DB: Java DB update failed: '--skip-java-db-update' cannot be specified on the first run\n",
      "2025-02-26T12:53:17: Call failed with error:\n",
      "\n",
      "2025-02-26T12:53:17: #### Exception encountered when generating sbom: Command '['trivy', 'image', '--no-progress', '--format', 'spdx-json', '--skip-db-update', '--skip-java-db-update', '--offline-scan', '--output', 'image-details.json', 'f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415:1', '--timeout', '10m0s']' returned non-zero exit status 1.\n",
      "2025-02-26T12:53:17: #### Cleaning up local image cache\n",
      "2025-02-26T12:53:17: Deleting f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io/azureml/azureml_cc48f16dfd4daa2effa03cfb0dd70415 from local machine\n",
      "2025-02-26T12:53:17: Error response from daemon: page not found\n",
      "\n",
      "\n",
      "2025-02-26T12:53:17: Logging out of Docker registry: f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io\n",
      "2025-02-26T12:53:17: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "2025-02-26T12:53:17: Logging out of Docker registry: f7c27ee9fb96407c9b8fa5c76209316e.azurecr.io\n",
      "2025-02-26T12:53:17: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: happy_gold_q5lypvqkw5\n",
      "Web View: https://ml.azure.com/runs/happy_gold_q5lypvqkw5?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.entities import ResourceConfiguration\n",
    "\n",
    "USE_BUILTIN_ENV = False\n",
    "str_command = \"\"\n",
    "\n",
    "if USE_BUILTIN_ENV:\n",
    "    str_env = \"azureml://registries/azureml/environments/acft-hf-nlp-gpu/versions/77\" # Use built-in Environment asset 这个是Asset ID，在AML对应的wrkspac/Enviroments菜单项/Curated env选项卡/选一个内置的env后在其详情页的overview选项卡中能找到\n",
    "    str_command += \"pip install -r requirements.txt && \" # requirements.txt在输入command函数的code参数指向的文件夹中\n",
    "else:\n",
    "    str_env = f\"{azure_env_name}@latest\" # Use Curated (built-in) Environment asset\n",
    "    \n",
    "# str_command += \"python train_mlflow.py \\\n",
    "#             --model_name_or_path ${{inputs.model_name_or_path}} \\\n",
    "#             --train_dir ${{inputs.train_dir}} \\\n",
    "#             --epochs ${{inputs.epoch}} \\\n",
    "#             --train_batch_size ${{inputs.train_batch_size}} \\\n",
    "#             --eval_batch_size ${{inputs.eval_batch_size}} \\\n",
    "#             --model_dir ${{inputs.model_dir}}\"\n",
    "str_command += \"python train_mlflow.py \\\n",
    "            --train_dir ${{inputs.train_dir}} \\\n",
    "            --model_dir ${{inputs.model_dir}}\" # command字符串引用的参数值都是从下面输入command的inputs dict中来的\n",
    "\n",
    "logger.info(f\"Env: {str_env}\")\n",
    "logger.info(f\"Command: {str_command}\")\n",
    "\n",
    "job = command(\n",
    "    inputs=dict( # 就是训练脚本src_train/train_mlflow.py的参数\n",
    "        # model_name_or_path=HF_MODEL_NAME_OR_PATH,\n",
    "        #train_dir=Input(type=\"uri_folder\", path=DATA_DIR), # Get data from local path\n",
    "        train_dir=Input(path=f\"{AZURE_DATA_NAME}@latest\"),  # Get data from Data asset\n",
    "        # epoch=d['train']['epoch'],\n",
    "        # train_batch_size=d['train']['train_batch_size'],\n",
    "        # eval_batch_size=d['train']['eval_batch_size'],  \n",
    "        model_dir=d['train']['model_dir']\n",
    "    ),\n",
    "    code=\"./src_train\",  # local path where the code is stored\n",
    "    compute=azure_compute_cluster_name,\n",
    "    command=str_command,\n",
    "    environment=str_env,\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1, # For multi-gpu training set this to an integer value more than 1\n",
    "    },\n",
    ")\n",
    "returned_job = ml_client.jobs.create_or_update(job, experiment_name='mlflwphi4') # Command/Spark objects can be used directly 创建并启动一个job. AIF没有，在AML对应的wrkspac/Jobs中\n",
    "logger.info(\"\"\"Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
    "required for training is automatically set up from Environment.\n",
    "\n",
    "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
    "\"\"\")\n",
    "ml_client.jobs.stream(returned_job.name)# 返回正在运行的job的日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>mlflwphi4</td><td>happy_gold_q5lypvqkw5</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/happy_gold_q5lypvqkw5?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'happy_gold_q5lypvqkw5', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://gitee.com/nilbody_0/reasoningimprove.git', 'mlflow.source.git.branch': 'master', 'mlflow.source.git.commit': '5abec4b0e126b4720b40b9a3ddefacd04bf291e8', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'gpu-h100', 'ContentSnapshotId': 'f737b133-ed9e-4f90-a5f0-c587402d2da7'}, 'print_as_yaml': False, 'id': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/jobs/happy_gold_q5lypvqkw5', 'Resource__source_path': '', 'base_path': '/mnt/d/BT/SRC/NLP/LLM/O1/reasoningimprove/phi4_rl', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0529232680>, 'serialize': <msrest.serialization.Serializer object at 0x7f05291597b0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'happy_gold_q5lypvqkw5', 'experiment_name': 'mlflwphi4', 'compute': 'gpu-h100', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/happy_gold_q5lypvqkw5?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'train_dir': {'type': 'uri_folder', 'path': 'lgds-gsm8k-main-demo:1', 'mode': 'ro_mount'}, 'model_dir': './outputs'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.happy_gold_q5lypvqkw5', 'mode': 'rw_mount'}}, 'inputs': {'train_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f052915b190>, 'model_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f0529159030>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f0529158970>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'happy_gold_q5lypvqkw5', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/d/BT/SRC/NLP/LLM/O1/reasoningimprove/phi4_rl', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0529232680>, 'serialize': <msrest.serialization.Serializer object at 0x7f0529159510>, 'command': 'python train_mlflow.py             --train_dir ${{inputs.train_dir}}             --model_dir ${{inputs.model_dir}}', 'code': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/codes/fd4bec24-38c4-41bf-8b2a-aa3ab4e8a3e3/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/environments/llm-sft-2024-11-05/versions/12', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f0529231e40>, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'happy_gold_q5lypvqkw5', 'is_deterministic': True, 'inputs': {'train_dir': {'type': 'uri_folder', 'path': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/data/lgds-gsm8k-main-demo/versions/1', 'mode': 'ro_mount'}, 'model_dir': {'type': 'string', 'default': './outputs'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.happy_gold_q5lypvqkw5', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/happy_gold_q5lypvqkw5?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0529232680>}, 'instance_id': 'df2aabbe-9d1f-4c95-8531-8d00daf930b7', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f0529231e40>, 'environment_variables': {}, 'environment': 'llm-sft-2024-11-05:12', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(returned_job)# 到这里时job已经执行完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the `trained_model` output is available\n",
    "job_name = returned_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. (Optional) Create model asset and get fine-tuned LLM to local folder\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1. Create model asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_model_asset(ml_client, model_name, job_name, model_dir=\"outputs\", model_type=\"custom_model\", update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Model asset, but will update the Model.')\n",
    "        else:\n",
    "            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)\n",
    "            logger.info(f\"Found Model asset: {model_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")        \n",
    "        model_path = f\"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/\"    \n",
    "        run_model = Model(\n",
    "            name=model_name,        \n",
    "            path=model_path,\n",
    "            description=\"Model created from run.\",\n",
    "            type=model_type # mlflow_model, custom_model, triton_model\n",
    "        )\n",
    "        model_asset = ml_client.models.create_or_update(run_model)# 在AML对应的wrkspac/Models中，目前AIF/AiPrj/Models只有deploy和service endpoint，而AML的还有权重文件\n",
    "        logger.info(f\"Created Model asset: {model_name}\")\n",
    "\n",
    "    return model_asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_type=\"custom_model` is intentional. This is because for newer models, MLflow's auto-logging compatibility is not as good and models need to be saved the traditional way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 21:18:51,490 - logger - INFO - Exception: (UserError) The specified resource was not found.\n",
      "Code: UserError\n",
      "Message: The specified resource was not found.\n",
      "Exception Details:\t(ModelNotFound) Model container with name: phi4-grpo-2024-11-05 not found.\n",
      "\tCode: ModelNotFound\n",
      "\tMessage: Model container with name: phi4-grpo-2024-11-05 not found.\n",
      "2025-02-26 21:18:57,620 - logger - INFO - Created Model asset: phi4-grpo-2024-11-05\n",
      "2025-02-26 21:18:57,621 - logger - INFO - ===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\n",
      "2025-02-26 21:18:57,622 - logger - INFO - azure_model_name=phi4-grpo-2024-11-05\n",
      "2025-02-26 21:18:57,623 - logger - INFO - model_dir=./outputs\n",
      "2025-02-26 21:18:57,628 - logger - INFO - model=creation_context:\n",
      "  created_at: '2025-02-26T13:18:56.848645+00:00'\n",
      "  created_by: Gang Luo\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2025-02-26T13:18:56.848645+00:00'\n",
      "  last_modified_by: Gang Luo\n",
      "  last_modified_by_type: User\n",
      "description: Model created from run.\n",
      "id: azureml:/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/mlw-pgwgybluulpec/models/phi4-grpo-2024-11-05/versions/1\n",
      "job_name: happy_gold_q5lypvqkw5\n",
      "name: phi4-grpo-2024-11-05\n",
      "path: azureml://subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/workspaces/mlw-pgwgybluulpec/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.happy_gold_q5lypvqkw5/outputs\n",
      "properties: {}\n",
      "stage: Development\n",
      "tags: {}\n",
      "type: custom_model\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "azure_model_name = d['serve']['azure_model_name']\n",
    "model_dir = d['train']['model_dir']\n",
    "model = get_or_create_model_asset(ml_client, azure_model_name, job_name, model_dir, model_type=\"custom_model\", update=False)\n",
    "\n",
    "logger.info(\"===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\")\n",
    "logger.info(f\"azure_model_name={azure_model_name}\")\n",
    "logger.info(f\"model_dir={model_dir}\")\n",
    "logger.info(f\"model={model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Get fine-tuned LLM to local folder\n",
    "\n",
    "You can copy it to your local directory to perform inference or serve the model in Azure environment. (e.g., real-time endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading the model ExperimentRun/dcid.happy_gold_q5lypvqkw5/outputs at ./artifact_downloads/phi4-grpo-2024-11-05/outputs\n",
      "\n",
      "Unable to stream download: HTTPSConnectionPool(host='stpgwgybluulpec.blob.core.windows.net', port=443): Read timed out.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='stpgwgybluulpec.blob.core.windows.net', port=443): Read timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:754\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 754\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:878\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m    879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt, read1\u001b[38;5;241m=\u001b[39mread1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/response.py:759\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BaseSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;66;03m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='stpgwgybluulpec.blob.core.windows.net', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m local_model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./artifact_downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(local_model_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mazure_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# 下载有可能需要开通Storage File Data Privileged Contributor跟Storage blob data contributor权限\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_model_operations.py:433\u001b[0m, in \u001b[0;36mModelOperations.download\u001b[0;34m(self, name, version, download_path)\u001b[0m\n\u001b[1;32m    431\u001b[0m     path_file \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(path_file, path\u001b[38;5;241m.\u001b[39mbasename(path_prefix\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m    432\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading the model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, path_prefix, path_file)\n\u001b[0;32m--> 433\u001b[0m \u001b[43mstorage_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarts_with\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_blob_storage_helper.py:275\u001b[0m, in \u001b[0;36mBlobStorageClient.download\u001b[0;34m(self, starts_with, destination, max_concurrency)\u001b[0m\n\u001b[1;32m    273\u001b[0m             file\u001b[38;5;241m.\u001b[39mwrite(blob_content)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    277\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving blob with prefix \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was unsuccessful. exception=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_blob_storage_helper.py:259\u001b[0m, in \u001b[0;36mBlobStorageClient.download\u001b[0;34m(self, starts_with, destination, max_concurrency)\u001b[0m\n\u001b[1;32m    256\u001b[0m     target_path\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m blob_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# check if total size of download has exceeded 100 MB\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# make sure proper cloud endpoint is used\u001b[39;00m\n\u001b[1;32m    263\u001b[0m cloud \u001b[38;5;241m=\u001b[39m _get_cloud_details()\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/storage/blob/_container_client.py:1316\u001b[0m, in \u001b[0;36mContainerClient.download_blob\u001b[0;34m(self, blob, offset, length, encoding, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m blob_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_blob_client(blob) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerge_span\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mblob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_blob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/storage/blob/_blob_client.py:753\u001b[0m, in \u001b[0;36mBlobClient.download_blob\u001b[0;34m(self, offset, length, encoding, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer provided encryption key must be used over HTTPS.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    736\u001b[0m options \u001b[38;5;241m=\u001b[39m _download_blob_options(\n\u001b[1;32m    737\u001b[0m     blob_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_name,\n\u001b[1;32m    738\u001b[0m     container_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStorageStreamDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/storage/blob/_download.py:403\u001b[0m, in \u001b[0;36mStorageStreamDownloader.__init__\u001b[0;34m(self, clients, config, start_range, end_range, validate_content, encryption_options, max_concurrency, name, container, encoding, download_cls, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m     initial_request_end \u001b[38;5;241m=\u001b[39m initial_request_start \u001b[38;5;241m+\u001b[39m first_get_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_offset \u001b[38;5;241m=\u001b[39m process_range_and_offset(\n\u001b[1;32m    396\u001b[0m     initial_request_start,\n\u001b[1;32m    397\u001b[0m     initial_request_end,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption_data\n\u001b[1;32m    401\u001b[0m )\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlobProperties\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response\u001b[38;5;241m.\u001b[39mproperties)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/storage/blob/_download.py:510\u001b[0m, in \u001b[0;36mStorageStreamDownloader._initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_content \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encryption_options\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (IncompleteReadError, HttpResponseError, DecodeError) \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/storage/blob/_download.py:66\u001b[0m, in \u001b[0;36mprocess_content\u001b[0;34m(data, start_offset, end_offset, encryption)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content \u001b[38;5;129;01mand\u001b[39;00m encryption\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m encryption\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolver\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/transport/_requests_basic.py:185\u001b[0m, in \u001b[0;36mStreamDownloadGenerator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m internal_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39minternal_response\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/models.py:826\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsSSLError(e)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='stpgwgybluulpec.blob.core.windows.net', port=443): Read timed out."
     ]
    }
   ],
   "source": [
    "# Download the model (this is optional) \n",
    "local_model_dir = \"./artifact_downloads\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "ml_client.models.download(name=azure_model_name, download_path=local_model_dir, version=model.version)# 下载有可能需要开通Storage File Data Privileged Contributor跟Storage blob data contributor权限"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf $DATA_DIR {local_model_dir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
