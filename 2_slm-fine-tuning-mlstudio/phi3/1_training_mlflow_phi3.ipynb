{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Open Source LLM using the Azure ML Python SDK (MLflow)\n",
    "\n",
    "### Overview\n",
    "\n",
    "Azure ML Workspace is compatible with MLflow and can be used as an MLflow Tracking Server, as described in the following official guide from Microsoft. MLflow provides features such as experiment tracking, model management, and model deployment, allowing you to manage data science and machine learning workflows more efficiently and systematically. Below are the main advantages of using Azure ML and MLflow together.\n",
    "\n",
    "#### 1. Experiment tracking and management\n",
    "\n",
    "You can systematically manage the parameters, metrics, and artifacts of all your experiments. Integrating with Azur eML allows you to easily track and manage this information within your Azure ML workspace.\n",
    "\n",
    "#### 2. Model management\n",
    "\n",
    "MLflow provides a model registry for model versioning. Integrate with AzureML to systematically manage and deploy all versions of your models. When combined with AzureML's deployment capabilities, models can be easily deployed to a variety of environments (e.g. Azure Kubernetes Service, Azure Container Instances).\n",
    "\n",
    "#### 3. Reproducibility and collaboration\n",
    "\n",
    "MLflow records the parameters and environment of every experiment, so you can accurately reproduce the experiment. This is very useful when you need to redo the same experiment across collaborating team members, or when you need to rerun an experiment at a later date.\n",
    "\n",
    "#### 4. CI/CD integration\n",
    "\n",
    "MLflow makes it easy to implement continuous integration (CI) and continuous deployment (CD) of machine learning models. Integrate with Azure DevOps or GitHub Actions to automatically run training, validation, and deployment processes as model changes occur.\n",
    "\n",
    "#### 5. Integrating Logging with HF\n",
    "\n",
    "When training a model with Hugging Face's Trainer API, if you specify `report_to=\"azure_ml\"`, basic indicators will be automatically logged without any additional code. Of course, you can freely log custom indicators using Bring Your Own Script like the conventional method, but Azure ML's basic logging function is also excellent, so try using it as a baseline.\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "---\n",
    "\n",
    "### Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: pythonundefinedundefinedundefinedjvsc74a57bd02139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "lab_prep_dir = os.getcwd().split(\"slm-innovator-lab\")[0] + \"slm-innovator-lab/0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(lab_prep_dir))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:26:06,630 - logger - INFO - ===== 0. Azure ML Training Info =====\n",
      "2024-12-12 15:26:06,636 - logger - INFO - AZURE_SUBSCRIPTION_ID=49aee8bf-3f02-464f-a0ba-e3467e7d85e2\n",
      "2024-12-12 15:26:06,645 - logger - INFO - AZURE_RESOURCE_GROUP=hubestus1grp\n",
      "2024-12-12 15:26:06,655 - logger - INFO - AZURE_WORKSPACE=lgestus1\n",
      "2024-12-12 15:26:06,660 - logger - INFO - AZURE_DATA_NAME=lgds-sftdemo241201\n",
      "2024-12-12 15:26:06,666 - logger - INFO - DATA_DIR=./dataset\n",
      "2024-12-12 15:26:06,671 - logger - INFO - CLOUD_DIR=./cloud\n",
      "2024-12-12 15:26:06,692 - logger - INFO - HF_MODEL_NAME_OR_PATH=microsoft/Phi-3.5-mini-instruct\n",
      "2024-12-12 15:26:06,698 - logger - INFO - IS_DEBUG=True\n",
      "2024-12-12 15:26:06,705 - logger - INFO - USE_LOWPRIORITY_VM=False\n",
      "2024-12-12 15:26:06,736 - logger - INFO - azure_env_name=lg-sftdemo-241201\n",
      "2024-12-12 15:26:06,742 - logger - INFO - azure_compute_cluster_name=ttt\n",
      "2024-12-12 15:26:06,748 - logger - INFO - azure_compute_cluster_size=Standard_NC40ads_H100_v5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from logger import logger\n",
    "from datetime import datetime\n",
    "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open('config_prd.yml') as f:\n",
    "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
    "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
    "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
    "AZURE_DATA_NAME = d['config']['AZURE_DATA_NAME']    \n",
    "DATA_DIR = d['config']['DATA_DIR']\n",
    "CLOUD_DIR = d['config']['CLOUD_DIR']\n",
    "HF_MODEL_NAME_OR_PATH = d['config']['HF_MODEL_NAME_OR_PATH']\n",
    "IS_DEBUG = d['config']['IS_DEBUG']\n",
    "USE_LOWPRIORITY_VM = d['config']['USE_LOWPRIORITY_VM']\n",
    "\n",
    "azure_env_name = d['train']['azure_env_name']  \n",
    "azure_compute_cluster_name = d['train']['azure_compute_cluster_name']\n",
    "azure_compute_cluster_size = d['train']['azure_compute_cluster_size']\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CLOUD_DIR, exist_ok=True)\n",
    "\n",
    "logger.info(\"===== 0. Azure ML Training Info =====\")\n",
    "logger.info(f\"AZURE_SUBSCRIPTION_ID={AZURE_SUBSCRIPTION_ID}\")\n",
    "logger.info(f\"AZURE_RESOURCE_GROUP={AZURE_RESOURCE_GROUP}\")\n",
    "logger.info(f\"AZURE_WORKSPACE={AZURE_WORKSPACE}\")\n",
    "logger.info(f\"AZURE_DATA_NAME={AZURE_DATA_NAME}\")\n",
    "logger.info(f\"DATA_DIR={DATA_DIR}\")\n",
    "logger.info(f\"CLOUD_DIR={CLOUD_DIR}\")\n",
    "logger.info(f\"HF_MODEL_NAME_OR_PATH={HF_MODEL_NAME_OR_PATH}\")\n",
    "logger.info(f\"IS_DEBUG={IS_DEBUG}\")\n",
    "logger.info(f\"USE_LOWPRIORITY_VM={USE_LOWPRIORITY_VM}\")\n",
    "\n",
    "logger.info(f\"azure_env_name={azure_env_name}\")\n",
    "logger.info(f\"azure_compute_cluster_name={azure_compute_cluster_name}\")\n",
    "logger.info(f\"azure_compute_cluster_size={azure_compute_cluster_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure workspace details\n",
    "\n",
    "To connect to a workspace, we need identifying parameters - a subscription, a resource group, and a workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle on the Azure Machine Learning workspace we need. We will use the default Azure authentication for this hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:26:15,101 - logger - INFO - ===== 2. Training preparation =====\n",
      "2024-12-12 15:26:15,109 - logger - INFO - Calling DefaultAzureCredential.\n",
      "Found the config file in: /afh/projects/lgestus1-a7b8ce59-78bb-44d3-bb36-eb2aebc0d778/config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7fe20ceb7910>,\n",
       "         subscription_id=49aee8bf-3f02-464f-a0ba-e3467e7d85e2,\n",
       "         resource_group_name=hubestus1grp,\n",
       "         workspace_name=lgestus1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml import Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
    "\n",
    "logger.info(f\"===== 2. Training preparation =====\")\n",
    "logger.info(f\"Calling DefaultAzureCredential.\")\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)  # 创建AML workspace client, 其实一个AIF ai prj就对应了一个AML wrkspac\n",
    "ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Dataset preparation\n",
    "\n",
    "---\n",
    "\n",
    "Preparing dataset is the first step in training a model. You can use the `datasets` library to load the dataset if you want to use Hugging Face datasets.<br>\n",
    "Otherwise, you can use your own dataset from previous hands-on sessions.\n",
    "\n",
    "We have prepared a dataset, [`lab1_augmented_samples.json`](lab1_augmented_samples.json), for this hands-on session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "USE_HF_DATASETS = False # Determine if we use Hugging Face Datasets or not\n",
    "\n",
    "import json\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "from logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:26:27,774 - logger - INFO - ===== 1. Custom Dataset preparation from Lab 1.  =====\n",
      "2024-12-12 15:26:27,780 - logger - INFO - Preparing dataset.\n",
      "2024-12-12 15:26:27,875 - logger - INFO - Save dataset to ./dataset\n"
     ]
    }
   ],
   "source": [
    "if not USE_HF_DATASETS:\n",
    "\n",
    "    # Function to load data from the provided file and convert to JSONL format for single-turn conversations\n",
    "    def load_and_convert_to_jsonl(file_path, system_prompt_msg=\"You're an AI assistant.\"):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for item in data:\n",
    "            jsonl_entry = {\n",
    "                \"prompt\": system_prompt_msg,\n",
    "                \"messages\": [\n",
    "                    {\"content\": item[\"input\"], \"role\": \"user\"},\n",
    "                    {\"content\": item[\"output\"], \"role\": \"assistant\"}\n",
    "                ]\n",
    "            }\n",
    "            result.append(json.dumps(jsonl_entry))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def save_jsonl_data(jsonl_data, file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            for entry in jsonl_data:\n",
    "                file.write(entry + '\\n')\n",
    "                \n",
    "    # Function to split data into training and testing sets\n",
    "    def split_train_test(jsonl_data, train_size=0.8):\n",
    "        # Shuffle the data\n",
    "        random.shuffle(jsonl_data)\n",
    "        \n",
    "        # Calculate split index\n",
    "        split_index = int(len(jsonl_data) * train_size)\n",
    "        \n",
    "        # Split the data\n",
    "        train_data = jsonl_data[:split_index]\n",
    "        test_data = jsonl_data[split_index:]\n",
    "        \n",
    "        return train_data, test_data            \n",
    "\n",
    "    logger.info(f\"===== 1. Custom Dataset preparation from Lab 1.  =====\")\n",
    "    logger.info(f\"Preparing dataset.\")\n",
    "    file_path = \"lab1_augmented_samples.json\"\n",
    "    system_prompt_msg = \"You are the SME (Subject Matter Expert) in Distributed training on Cloud. Please answer the questions accurately.\"\n",
    "    jsonl_dataset = load_and_convert_to_jsonl(file_path, system_prompt_msg) # 转成训练数据的格式\n",
    "    train_dataset, test_dataset = split_train_test(jsonl_dataset, train_size=0.8)\n",
    "    logger.info(f\"Save dataset to {DATA_DIR}\")\n",
    "    save_jsonl_data(train_dataset, f\"{DATA_DIR}/train.jsonl\")\n",
    "    save_jsonl_data(test_dataset, f\"{DATA_DIR}/eval.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data can be used as a dataset stored in the local development environment, but can also be registered as AzureML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_data_asset(ml_client, data_name, data_local_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_data_version = max([int(d.version) for d in ml_client.data.list(name=data_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Data asset, but will update the Data.')            \n",
    "        else:\n",
    "            data_asset = ml_client.data.get(name=data_name, version=latest_data_version)\n",
    "            logger.info(f\"Found Data asset: {data_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        data = Data(\n",
    "            path=data_local_dir,\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            description=f\"{data_name} for fine tuning\",\n",
    "            tags={\"FineTuningType\": \"Instruction\", \"Language\": \"En\"},\n",
    "            name=data_name\n",
    "        )\n",
    "        data_asset = ml_client.data.create_or_update(data)#AIF/AiPrj/Data+idx中；AML对应的wrkspac/Data中\n",
    "        logger.info(f\"Created/Updated Data asset: {data_name}\")\n",
    "        \n",
    "    return data_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:26:42,114 - logger - INFO - Found Data asset: lgds-sftdemo241201. Will not create again\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_context:\n",
      "  created_at: '2024-12-12T09:49:39.107477+00:00'\n",
      "  created_by: Gang Luo\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2024-12-12T09:49:39.123409+00:00'\n",
      "description: lgds-sftdemo241201 for fine tuning\n",
      "id: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/data/lgds-sftdemo241201/versions/1\n",
      "name: lgds-sftdemo241201\n",
      "path: azureml://subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1/datastores/workspaceblobstore/paths/LocalUpload/819c5f5bf03c65565c26eb498603d5ce/dataset/\n",
      "properties: {}\n",
      "tags:\n",
      "  FineTuningType: Instruction\n",
      "  Language: En\n",
      "type: uri_folder\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_or_create_data_asset(ml_client, AZURE_DATA_NAME, data_local_dir=DATA_DIR, update=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Training preparation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Create AzureML environment\n",
    "Azure ML defines containers (called environment asset) in which your code will run. We can use the built-in environment or build a custom environment (Docker container, conda).\n",
    "This hands-on uses conda yaml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./cloud/train/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CLOUD_DIR}/train/Dockerfile\n",
    "FROM mcr.microsoft.com/aifx/acpt/stable-ubuntu2004-cu124-py310-torch241:biweekly.202410.2\n",
    "\n",
    "USER root\n",
    "\n",
    "# support Deepspeed launcher requirement of passwordless ssh login\n",
    "RUN apt-get update && apt-get -y upgrade\n",
    "RUN pip install --upgrade pip\n",
    "RUN apt-get install -y openssh-server openssh-client\n",
    "\n",
    "# Install pip dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt --no-cache-dir\n",
    "\n",
    "RUN MAX_JOBS=4 pip install flash-attn==2.6.3 --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./cloud/train/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CLOUD_DIR}/train/requirements.txt\n",
    "azureml-acft-accelerator==0.0.63\n",
    "azureml_acft_common_components==0.0.63\n",
    "azureml-acft-contrib-hf-nlp==0.0.63\n",
    "azureml-evaluate-mlflow==0.0.63\n",
    "azureml-metrics[text]==0.0.63\n",
    "mltable==1.6.1\n",
    "mpi4py==4.0.1\n",
    "sentencepiece==0.2.0\n",
    "transformers==4.46.1\n",
    "datasets==3.1.0\n",
    "accelerate==1.1.0\n",
    "diffusers==0.31.0\n",
    "onnxruntime==1.20.0\n",
    "rouge-score==0.1.2\n",
    "sacrebleu==2.4.3\n",
    "bitsandbytes==0.44.1\n",
    "einops==0.8.0\n",
    "aiohttp==3.10.10\n",
    "peft==0.13.2\n",
    "deepspeed==0.15.3\n",
    "trl==0.12.0\n",
    "tiktoken==0.8.0\n",
    "packaging==24.1\n",
    "timm==1.0.11\n",
    "azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_or_create_docker_environment_asset(ml_client, env_name, docker_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
    "        else:\n",
    "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
    "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")\n",
    "        env_docker_image = Environment(\n",
    "            build=BuildContext(path=docker_dir),\n",
    "            name=env_name,\n",
    "            description=\"Environment created from a Docker context.\",\n",
    "        )\n",
    "        env_asset = ml_client.environments.create_or_update(env_docker_image)#AIF没有,但AIF/Code有用到一个内置的env。真身在AML对应的wrkspac/Environments中\n",
    "        logger.info(f\"Created Environment asset: {env_name}\")\n",
    "    \n",
    "    return env_asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:27:14,316 - logger - INFO - Found Environment asset: lg-sftdemo-241201. Will not create again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'lg-sftdemo-241201', 'description': 'Environment created from a Docker context.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/environments/lg-sftdemo-241201/versions/1', 'Resource__source_path': '', 'base_path': '/afh/projects/lgestus1-a7b8ce59-78bb-44d3-bb36-eb2aebc0d778/shared/Users/luogang/SRC/slm-innovator-lab/2_slm-fine-tuning-mlstudio/phi3', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe1d2013310>, 'serialize': <msrest.serialization.Serializer object at 0x7fe1d2011030>, 'version': '1', 'conda_file': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7fe1d20128c0>, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_or_create_docker_environment_asset(ml_client, azure_env_name, docker_dir=f\"{CLOUD_DIR}/train\", update=False)\n",
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Training\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1. Create the compute cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:27:21,154 - logger - INFO - ===== 3. Training =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:27:21,529 - logger - INFO - The compute cluster already exists! Reusing it for the current run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_on: 2024-12-12T14:10:53.691817+0000\n",
      "enable_node_public_ip: true\n",
      "enable_os_patching: false\n",
      "enable_root_access: true\n",
      "enable_sso: true\n",
      "id: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/hubestus1/computes/ttt\n",
      "idle_time_before_shutdown: PT60M\n",
      "idle_time_before_shutdown_minutes: 60\n",
      "last_operation:\n",
      "  operation_name: Stop\n",
      "  operation_status: Succeeded\n",
      "  operation_time: '2024-12-12T15:17:50.394Z'\n",
      "  operation_trigger: IdleShutdown\n",
      "location: eastus\n",
      "name: ttt\n",
      "network_settings:\n",
      "  private_ip_address: 10.0.0.4\n",
      "  public_ip_address: 4.227.194.93\n",
      "os_image_metadata:\n",
      "  current_image_version: 24.10.24\n",
      "  is_latest_os_image_version: true\n",
      "  latest_image_version: 24.10.24\n",
      "provisioning_state: Succeeded\n",
      "release_quota_on_stop: false\n",
      "services:\n",
      "- display_name: Jupyter\n",
      "  endpoint_uri: https://ttt.eastus.instances.azureml.ms/tree/\n",
      "- display_name: Jupyter Lab\n",
      "  endpoint_uri: https://ttt.eastus.instances.azureml.ms/lab\n",
      "size: Standard_NC40ads_H100_v5\n",
      "ssh_public_access_enabled: false\n",
      "ssh_settings:\n",
      "  admin_username: azureuser\n",
      "  ssh_port: '50000'\n",
      "state: Stopped\n",
      "type: computeinstance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "logger.info(f\"===== 3. Training =====\")\n",
    "### Create the compute cluster\n",
    "try:\n",
    "    compute = ml_client.compute.get(azure_compute_cluster_name)\n",
    "    logger.info(\"The compute cluster already exists! Reusing it for the current run\")\n",
    "except Exception as ex:\n",
    "    logger.info(\n",
    "        f\"Looks like the compute cluster doesn't exist. Creating a new one with compute size {azure_compute_cluster_size}!\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Attempt #1 - Trying to create a dedicated compute\")\n",
    "        tier = 'LowPriority' if USE_LOWPRIORITY_VM else 'Dedicated'\n",
    "        compute = AmlCompute(\n",
    "            name=azure_compute_cluster_name,\n",
    "            size=azure_compute_cluster_size, # Standard_NC40ads_H100_v5\n",
    "            tier=tier,\n",
    "            max_instances=1,  # For multi node training set this to an integer value more than 1\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute).wait()#AIF/ai prj/->management center/对应的hub那一组菜单项/Compute。要修改Compute所需的CPU/GPU Quota则在同一个management center页面菜单中选择Quota\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error: {e}\")\n",
    "print(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize src_train/train_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Start training job\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "\n",
    "-   `inputs` - This is the dictionary of inputs using name value pairs to the command.\n",
    "    -   `type` - The type of input. This can be a `uri_file` or `uri_folder`. The default is `uri_folder`.\n",
    "    -   `path` - The path to the file or folder. These can be local or remote files or folders. For remote files - http/https, wasb are supported.\n",
    "        -   Azure ML `data`/`dataset` or `datastore` are of type `uri_folder`. To use `data`/`dataset` as input, you can use registered dataset in the workspace using the format '<data_name>:<version>'. For e.g Input(type='uri_folder', path='my_dataset:1')\n",
    "    -   `mode` - Mode of how the data should be delivered to the compute target. Allowed values are `ro_mount`, `rw_mount` and `download`. Default is `ro_mount`\n",
    "-   `code` - This is the path where the code to run the command is located\n",
    "-   `compute` - The compute on which the command will run. You can run it on the local machine by using `local` for the compute.\n",
    "-   `command` - This is the command that needs to be run\n",
    "    in the `command` using the `${{inputs.<input_name>}}` expression. To use files or folders as inputs, we can use the `Input` class. The `Input` class supports three parameters:\n",
    "-   `environment` - This is the environment needed for the command to run. Curated (built-in) or custom environments from the workspace can be used.\n",
    "-   `instance_count` - Number of nodes. Default is 1.\n",
    "-   `distribution` - Distribution configuration for distributed training scenarios. Azure Machine Learning supports PyTorch, TensorFlow, and MPI-based distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:48:22,920 - logger - INFO - Env: lg-sftdemo-241201@latest\n",
      "2024-12-12 15:48:22,927 - logger - INFO - Command: python train_mlflow.py             --model_name_or_path ${{inputs.model_name_or_path}}             --train_dir ${{inputs.train_dir}}             --epochs ${{inputs.epoch}}             --train_batch_size ${{inputs.train_batch_size}}             --eval_batch_size ${{inputs.eval_batch_size}}             --model_dir ${{inputs.model_dir}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:48:26,428 - logger - INFO - Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
      "required for training is automatically set up from Environment.\n",
      "\n",
      "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: clever_nutmeg_n0yzztn0qw\n",
      "Web View: https://ml.azure.com/runs/clever_nutmeg_n0yzztn0qw?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: clever_nutmeg_n0yzztn0qw\n",
      "Web View: https://ml.azure.com/runs/clever_nutmeg_n0yzztn0qw?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.entities import ResourceConfiguration\n",
    "\n",
    "USE_BUILTIN_ENV = False\n",
    "str_command = \"\"\n",
    "\n",
    "if USE_BUILTIN_ENV:\n",
    "    str_env = \"azureml://registries/azureml/environments/acft-hf-nlp-gpu/versions/77\" # Use built-in Environment asset 这个是Asset ID，在AML对应的wrkspac/Enviroments菜单项/Curated env选项卡/选一个内置的env后在其详情页的overview选项卡中能找到\n",
    "    str_command += \"pip install -r requirements.txt && \" # requirements.txt在输入command函数的code参数指向的文件夹中\n",
    "else:\n",
    "    str_env = f\"{azure_env_name}@latest\" # Use Curated (built-in) Environment asset\n",
    "    \n",
    "str_command += \"python train_mlflow.py \\\n",
    "            --model_name_or_path ${{inputs.model_name_or_path}} \\\n",
    "            --train_dir ${{inputs.train_dir}} \\\n",
    "            --epochs ${{inputs.epoch}} \\\n",
    "            --train_batch_size ${{inputs.train_batch_size}} \\\n",
    "            --eval_batch_size ${{inputs.eval_batch_size}} \\\n",
    "            --model_dir ${{inputs.model_dir}}\" # command字符串引用的参数值都是从下面输入command的inputs dict中来的\n",
    "\n",
    "logger.info(f\"Env: {str_env}\")\n",
    "logger.info(f\"Command: {str_command}\")\n",
    "\n",
    "job = command(\n",
    "    inputs=dict( # 就是训练脚本src_train/train_mlflow.py的参数\n",
    "        model_name_or_path=HF_MODEL_NAME_OR_PATH,\n",
    "        #train_dir=Input(type=\"uri_folder\", path=DATA_DIR), # Get data from local path\n",
    "        train_dir=Input(path=f\"{AZURE_DATA_NAME}@latest\"),  # Get data from Data asset\n",
    "        epoch=d['train']['epoch'],\n",
    "        train_batch_size=d['train']['train_batch_size'],\n",
    "        eval_batch_size=d['train']['eval_batch_size'],  \n",
    "        model_dir=d['train']['model_dir']\n",
    "    ),\n",
    "    code=\"./src_train\",  # local path where the code is stored\n",
    "    compute=azure_compute_cluster_name,\n",
    "    command=str_command,\n",
    "    environment=str_env,\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1, # For multi-gpu training set this to an integer value more than 1\n",
    "    },\n",
    ")\n",
    "returned_job = ml_client.jobs.create_or_update(job, experiment_name='mlflwphi3') # Command/Spark objects can be used directly 创建并启动一个job. AIF没有，在AML对应的wrkspac/Jobs中\n",
    "logger.info(\"\"\"Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
    "required for training is automatically set up from Environment.\n",
    "\n",
    "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
    "\"\"\")\n",
    "ml_client.jobs.stream(returned_job.name)# 返回正在运行的job的日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>mlflwphi3</td><td>clever_nutmeg_n0yzztn0qw</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/clever_nutmeg_n0yzztn0qw?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'clever_nutmeg_n0yzztn0qw', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://gitee.com/nilbody_0/slm-innovator-lab.git', 'mlflow.source.git.branch': 'bt241114_1', 'mlflow.source.git.commit': '226b2daf2266d667efca4300143af1f7bcec92d3', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlcdsi', '_azureml.ClusterName': 'ttt', 'ContentSnapshotId': '678f6390-bbe1-41c6-af7a-99cd84822b91'}, 'print_as_yaml': False, 'id': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/jobs/clever_nutmeg_n0yzztn0qw', 'Resource__source_path': '', 'base_path': '/afh/projects/lgestus1-a7b8ce59-78bb-44d3-bb36-eb2aebc0d778/shared/Users/luogang/SRC/slm-innovator-lab/2_slm-fine-tuning-mlstudio/phi3', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe1d1444f10>, 'serialize': <msrest.serialization.Serializer object at 0x7fe1d21ccd90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'clever_nutmeg_n0yzztn0qw', 'experiment_name': 'mlflwphi3', 'compute': 'ttt', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/clever_nutmeg_n0yzztn0qw?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'model_name_or_path': 'microsoft/Phi-3.5-mini-instruct', 'train_dir': {'type': 'uri_folder', 'path': 'lgds-sftdemo241201:1', 'mode': 'ro_mount'}, 'epoch': '1', 'train_batch_size': '8', 'eval_batch_size': '8', 'model_dir': './outputs'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.clever_nutmeg_n0yzztn0qw', 'mode': 'rw_mount'}}, 'inputs': {'model_name_or_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21cff40>, 'train_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21cc400>, 'epoch': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21cfbe0>, 'train_batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21ce410>, 'eval_batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21cf9d0>, 'model_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe1d21cf280>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fe1d21cd120>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'clever_nutmeg_n0yzztn0qw', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/afh/projects/lgestus1-a7b8ce59-78bb-44d3-bb36-eb2aebc0d778/shared/Users/luogang/SRC/slm-innovator-lab/2_slm-fine-tuning-mlstudio/phi3', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe1d1444f10>, 'serialize': <msrest.serialization.Serializer object at 0x7fe1d14443a0>, 'command': 'python train_mlflow.py             --model_name_or_path ${{inputs.model_name_or_path}}             --train_dir ${{inputs.train_dir}}             --epochs ${{inputs.epoch}}             --train_batch_size ${{inputs.train_batch_size}}             --eval_batch_size ${{inputs.eval_batch_size}}             --model_dir ${{inputs.model_dir}}', 'code': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/codes/bd32f2f6-badd-4fef-98cf-445e9ce23e7b/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/environments/lg-sftdemo-241201/versions/1', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7fe1d1444220>, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'clever_nutmeg_n0yzztn0qw', 'is_deterministic': True, 'inputs': {'model_name_or_path': {'type': 'string', 'default': 'microsoft/Phi-3.5-mini-instruct'}, 'train_dir': {'type': 'uri_folder', 'path': '/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/data/lgds-sftdemo241201/versions/1', 'mode': 'ro_mount'}, 'epoch': {'type': 'string', 'default': '1'}, 'train_batch_size': {'type': 'string', 'default': '8'}, 'eval_batch_size': {'type': 'string', 'default': '8'}, 'model_dir': {'type': 'string', 'default': './outputs'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.clever_nutmeg_n0yzztn0qw', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/clever_nutmeg_n0yzztn0qw?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/hubestus1grp/workspaces/lgestus1&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe1d1444f10>}, 'instance_id': 'f2226775-b803-4553-ade0-82e427c6fe93', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7fe1d1444220>, 'environment_variables': {}, 'environment': 'lg-sftdemo-241201:1', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(returned_job)# 到这里时job已经执行完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the `trained_model` output is available\n",
    "job_name = returned_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. (Optional) Create model asset and get fine-tuned LLM to local folder\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1. Create model asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_model_asset(ml_client, model_name, job_name, model_dir=\"outputs\", model_type=\"custom_model\", update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Model asset, but will update the Model.')\n",
    "        else:\n",
    "            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)\n",
    "            logger.info(f\"Found Model asset: {model_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")        \n",
    "        model_path = f\"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/\"    \n",
    "        run_model = Model(\n",
    "            name=model_name,        \n",
    "            path=model_path,\n",
    "            description=\"Model created from run.\",\n",
    "            type=model_type # mlflow_model, custom_model, triton_model\n",
    "        )\n",
    "        model_asset = ml_client.models.create_or_update(run_model)# 在AML对应的wrkspac/Models中，目前AIF/AiPrj/Models只有deploy和service endpoint，而AML的还有权重文件\n",
    "        logger.info(f\"Created Model asset: {model_name}\")\n",
    "\n",
    "    return model_asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_type=\"custom_model` is intentional. This is because for newer models, MLflow's auto-logging compatibility is not as good and models need to be saved the traditional way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 16:19:03,932 - logger - INFO - Exception: (UserError) The specified resource was not found.\n",
      "Code: UserError\n",
      "Message: The specified resource was not found.\n",
      "Exception Details:\t(ModelNotFound) Model container with name: phi3-sft-241201 not found.\n",
      "\tCode: ModelNotFound\n",
      "\tMessage: Model container with name: phi3-sft-241201 not found.\n",
      "2024-12-12 16:19:06,132 - logger - INFO - Created Model asset: phi3-sft-241201\n",
      "2024-12-12 16:19:06,133 - logger - INFO - ===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\n",
      "2024-12-12 16:19:06,134 - logger - INFO - azure_model_name=phi3-sft-241201\n",
      "2024-12-12 16:19:06,135 - logger - INFO - model_dir=./outputs\n",
      "2024-12-12 16:19:06,138 - logger - INFO - model=creation_context:\n",
      "  created_at: '2024-12-12T16:19:05.230437+00:00'\n",
      "  created_by: Gang Luo\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2024-12-12T16:19:05.230437+00:00'\n",
      "  last_modified_by: Gang Luo\n",
      "  last_modified_by_type: User\n",
      "description: Model created from run.\n",
      "id: azureml:/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/providers/Microsoft.MachineLearningServices/workspaces/lgestus1/models/phi3-sft-241201/versions/1\n",
      "job_name: clever_nutmeg_n0yzztn0qw\n",
      "name: phi3-sft-241201\n",
      "path: azureml://subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/hubestus1grp/workspaces/lgestus1/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.clever_nutmeg_n0yzztn0qw/outputs\n",
      "properties: {}\n",
      "stage: Development\n",
      "tags: {}\n",
      "type: custom_model\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "azure_model_name = d['serve']['azure_model_name']\n",
    "model_dir = d['train']['model_dir']\n",
    "model = get_or_create_model_asset(ml_client, azure_model_name, job_name, model_dir, model_type=\"custom_model\", update=False)\n",
    "\n",
    "logger.info(\"===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\")\n",
    "logger.info(f\"azure_model_name={azure_model_name}\")\n",
    "logger.info(f\"model_dir={model_dir}\")\n",
    "logger.info(f\"model={model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Get fine-tuned LLM to local folder\n",
    "\n",
    "You can copy it to your local directory to perform inference or serve the model in Azure environment. (e.g., real-time endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading the model ExperimentRun/dcid.clever_nutmeg_n0yzztn0qw/outputs at ./artifact_downloads/phi3-sft-241201/outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the model (this is optional) \n",
    "local_model_dir = \"./artifact_downloads\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "ml_client.models.download(name=azure_model_name, download_path=local_model_dir, version=model.version)# 下载有可能需要开通Storage File Data Privileged Contributor跟Storage blob data contributor权限"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf $DATA_DIR {local_model_dir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
