{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run chat flows using Promptflow Python SDK\n",
    "\n",
    "### Overview\n",
    "\n",
    "Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality.\n",
    "\n",
    "In this hands-on, you will be able to:\n",
    "Create flows that link fine-tuned phi3.5 endpoint(Python code) and gpt model in a executable workflow.\n",
    "Debug and iterate your flows, especially tracing interaction with LLMs with ease.\n",
    "\n",
    "#### 1. Set up Promptflow client with Credential and configuration\n",
    "\n",
    "#### 2. Create a new chat flow by providing the flow name and description.\n",
    "\n",
    "#### 3. Run Basic Promptflow with questions to compare models\n",
    "\n",
    "#### 4. Run Context Added Promptflow with the outdoor questions\n",
    "\n",
    "#### 5. Use serverless endpoint to run the Promptflow with context\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Kernel: pythonundefinedundefinedundefinedjvsc74a57bd02139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "lab_prep_dir = os.getcwd().split(\"SLMWorkshopCN\")[0] + \"SLMWorkshopCN/0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(lab_prep_dir))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49aee8bf-3f02-464f-a0ba-e3467e7d85e2\n",
      "es1u1aif1grp\n",
      "esu1aif1prj\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import required libraries\n",
    "from promptflow.azure import PFClient\n",
    "from promptflow.entities import Run\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, InteractiveBrowserCredential\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "load_dotenv()\n",
    "with open('./config_prd.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(config[\"subscription_id\"])\n",
    "print(config[\"resource_group\"])\n",
    "print(config[\"workspace_name\"]) # Azure AI Studio project name which is not the same as the Azure ML workspace name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_status(pf_azure_client:PFClient, run_result:Run):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = pf_azure_client.runs.get(run_result).status\n",
    "        if status == \"Preparing\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Completed\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = pf_azure_client.runs.get(run_result).status\n",
    "        pbar.update(1)\n",
    "        print(\"Promptflow Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up Promptflow client with Credential and configuration\n",
    "\n",
    "-   Create a promptflow client with the credential and configuration. You need to set the `config_prd.json` file with subscription_id, resource_group and workspace_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config_prd.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure AI Studio Workspace: esu1aif1prj\n",
      "Workspace Location: eastus\n",
      "Workspace ID: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/es1u1aif1grp/providers/Microsoft.MachineLearningServices/workspaces/esu1aif1prj\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "# if you cannot use DefaultAzureCredential and InteractiveBrowserCredential you need to set up the Managed identity in your .env file\n",
    "\n",
    "pf_azure_client = PFClient.from_config(credential=credential, path=\"./config_prd.json\")\n",
    "\n",
    "# pf_azure_client = PFClient(credential=credential, \n",
    "#                            subscription_id=\"your subscription id\", \n",
    "#                            resource_group_name=\"your resource group name\", \n",
    "#                            workspace_name=\"your workspace name\")            \n",
    "\n",
    "try:\n",
    "    workspace = pf_azure_client.ml_client.workspaces.get(name=config[\"workspace_name\"])\n",
    "    print(f\"Connected to Azure AI Studio Workspace: {workspace.name}\")\n",
    "    print(f\"Workspace Location: {workspace.location}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Failed to connect to Azure ML Workspace: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a new chat flow by providing the flow name and description.\n",
    "\n",
    "-   Create a new chat flow by providing the flow name and description. You can view and clone the flow on Azure AI studio UI.\n",
    "\n",
    "> ✨ **_important_** <br>\n",
    "> Grant the Storage File Data Privileged Contributor, Storage Blob Data Contributor at the storage of AI studiorole to user, group, service principle and managed Identity which you are trying to access, you can execute the code below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the exist connections\n",
    "\n",
    "-   currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace.\n",
    "    > ✨ **_important_** <br>\n",
    "    > Update flow.dag.yaml files in your flow_path with the connection name you have created in the Azure ML Studio UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
      "environment:\n",
      "  python_requirements_txt: requirements.txt\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "    is_chat_input: true\n",
      "    default: What is the capital of France?\n",
      "outputs:\n",
      "  phi35_answer:\n",
      "    type: string\n",
      "    reference: ${phi35.output}\n",
      "    is_chat_output: false\n",
      "  gpt4o_answer:\n",
      "    type: string\n",
      "    reference: ${gpt4o.output}\n",
      "    is_chat_output: true\n",
      "nodes:\n",
      "- name: phi35\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: phi35_finetuned.py\n",
      "  inputs:\n",
      "    connection: coneu1-phi3-endpoint-241201\n",
      "    input_data: ${inputs.question}\n",
      "- name: gpt4o\n",
      "  type: llm\n",
      "  source:\n",
      "    type: code\n",
      "    path: chat.jinja2\n",
      "  inputs:\n",
      "    deployment_name: gpt-4o\n",
      "    temperature: 0.7\n",
      "    top_p: 1\n",
      "    max_tokens: 256\n",
      "    question: ${inputs.question}\n",
      "  connection: aoai-tst1\n",
      "  api: chat\n",
      "  module: promptflow.tools.aoai\n",
      "  use_variants: false\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "# Read the template file\n",
    "template = env.get_template('./flow-template/chat.flow.dag.yaml')\n",
    "\n",
    "# Define the variables for the template\n",
    "variables = {\n",
    "\t\"your_phi35_connection_name\": \"coneu1-phi3-endpoint-241201\",\n",
    "\t\"your_gpt4o_connection_name\": \"aoai-tst1\",\n",
    "}\n",
    "\n",
    "rendered_content = template.render(variables)\n",
    "Path('./chat/flow.dag.yaml').write_text(rendered_content)\n",
    "\n",
    "print(Path('./chat/flow.dag.yaml').read_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow created successfully:\n",
      "{\n",
      "    \"name\": \"93a899e9-7106-4633-9329-3eef4ecc9898\",\n",
      "    \"type\": \"chat\",\n",
      "    \"description\": \"fine-tuned model comparison flow\",\n",
      "    \"path\": \"Users/luogang/promptflow/chat-12-15-2024-08-19-36/flow.dag.yaml\",\n",
      "    \"code\": \"azureml://locations/eastus/workspaces/6f6dfe14-cbed-4c2f-8e06-39f5bfbc7aaf/flows/93a899e9-7106-4633-9329-3eef4ecc9898\",\n",
      "    \"display_name\": \"comparison flow created from python sdk\",\n",
      "    \"owner\": {\n",
      "        \"user_object_id\": \"a0490c2e-4f6d-490a-9f03-0b49b8a3c480\",\n",
      "        \"user_tenant_id\": \"16b3c013-d300-468d-ac64-7eda0820b6d3\",\n",
      "        \"user_name\": \"Gang Luo\"\n",
      "    },\n",
      "    \"is_archived\": false,\n",
      "    \"created_date\": \"2024-12-15 08:19:44.673901+00:00\",\n",
      "    \"flow_portal_url\": \"https://ai.azure.com/projectflows/93a899e9-7106-4633-9329-3eef4ecc9898/6f6dfe14-cbed-4c2f-8e06-39f5bfbc7aaf/details/Flow?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/es1u1aif1grp/providers/Microsoft.MachineLearningServices/workspaces/esu1aif1prj\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<promptflow.azure._entities._flow.Flow at 0x7fb825419e40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grant the right accessibility to create the flow \n",
    "pf_azure_client.flows.create_or_update(flow=\"chat/\", type=\"chat\", display_name=\"comparison flow created from python sdk\", description=\"fine-tuned model comparison flow\")#在AI Foundry/AI Project/Prompt Flow/Flow标签页中可看到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Basic Promptflow with questions to compare models\n",
    "\n",
    "-   Run the Promptflow with the simple questions such as \"What is the capital of France?\" and compare the results of the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading questions_basic.jsonl\u001b[32m (< 1 MB): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 724/724 [00:00<00:00, 7.96kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading chat (0.01 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5696/5696 [00:00<00:00, 17692.10it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-12-15 08:19:48 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-12-15 08:19:48 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_variant_0_20241215_081945_455389/details?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/es1u1aif1grp/providers/Microsoft.MachineLearningServices/workspaces/esu1aif1prj\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat\"\n",
    "data_path = \"./data/questions_basic.jsonl\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\"\n",
    "}\n",
    "\n",
    "run_result = pf_azure_client.run(#在AI Foundry/AI Project/Prompt Flow/Runs标签页中可看到，这里代码提交的run与上面pf_azure_client.flows.create_or_update创建的flow并无关联，只是丢个xml上去跑而已\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path,\n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_with_data\",\n",
    "    tags={\"chat_with_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:45<01:31, 45.63s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [00:56<00:25, 25.36s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:07<00:00, 22.65s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the center of Seoul?</td>\n",
       "      <td>0</td>\n",
       "      <td>The center of Seoul is often considered to be...</td>\n",
       "      <td>The center of Seoul is often considered to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>1</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me about the brief history of Microsoft</td>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft was founded by Bill Gates and Paul ...</td>\n",
       "      <td>Microsoft was founded by Bill Gates and Paul A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who wrote Romeo and Juliet?</td>\n",
       "      <td>3</td>\n",
       "      <td>William Shakespeare wrote \"Romeo and Juliet.\"</td>\n",
       "      <td>William Shakespeare wrote \"Romeo and Juliet.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does HTML stand for?</td>\n",
       "      <td>4</td>\n",
       "      <td>HTML stands for HyperText Markup Language. It...</td>\n",
       "      <td>HTML stands for HyperText Markup Language.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>5</td>\n",
       "      <td>The Mona Lisa was painted by Leonardo da Vinci.</td>\n",
       "      <td>Leonardo da Vinci painted the Mona Lisa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>6</td>\n",
       "      <td>Jupiter is the largest planet in our solar sy...</td>\n",
       "      <td>The largest planet in our solar system is Jupi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who won the Nobel Prize in Literature in 2024?</td>\n",
       "      <td>7</td>\n",
       "      <td>I'm sorry, but as of my knowledge cutoff in e...</td>\n",
       "      <td>I'm sorry, but I don't have information about ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inputs.question  \\\n",
       "outputs.line_number                                                    \n",
       "0                                       what is the center of Seoul?   \n",
       "1                                     What is the capital of France?   \n",
       "2                       Tell me about the brief history of Microsoft   \n",
       "3                                        Who wrote Romeo and Juliet?   \n",
       "4                                          What does HTML stand for?   \n",
       "5                                         Who painted the Mona Lisa?   \n",
       "6                    What is the largest planet in our solar system?   \n",
       "7                     Who won the Nobel Prize in Literature in 2024?   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "5                                     5   \n",
       "6                                     6   \n",
       "7                                     7   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     The center of Seoul is often considered to be...   \n",
       "1                                      The capital of France is Paris.   \n",
       "2                     Microsoft was founded by Bill Gates and Paul ...   \n",
       "3                        William Shakespeare wrote \"Romeo and Juliet.\"   \n",
       "4                     HTML stands for HyperText Markup Language. It...   \n",
       "5                      The Mona Lisa was painted by Leonardo da Vinci.   \n",
       "6                     Jupiter is the largest planet in our solar sy...   \n",
       "7                     I'm sorry, but as of my knowledge cutoff in e...   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    The center of Seoul is often considered to be ...  \n",
       "1                                      The capital of France is Paris.  \n",
       "2                    Microsoft was founded by Bill Gates and Paul A...  \n",
       "3                        William Shakespeare wrote \"Romeo and Juliet.\"  \n",
       "4                           HTML stands for HyperText Markup Language.  \n",
       "5                             Leonardo da Vinci painted the Mona Lisa.  \n",
       "6                    The largest planet in our solar system is Jupi...  \n",
       "7                    I'm sorry, but I don't have information about ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Context Added Promptflow with the outdoor questions\n",
    "\n",
    "-   Run the Promptflow using the context data and ask the outdoor product related questions to compare the results of the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the exist connections\n",
    "\n",
    "-   currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace.\n",
    "    > ✨ **_important_** <br>\n",
    "    > Update flow.dag.yaml files in your flow_path with the connection name you have created in the Azure ML Studio UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
      "environment:\n",
      "  python_requirements_txt: requirements.txt\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "    is_chat_input: true\n",
      "    default: What is the capital of France?\n",
      "  context:\n",
      "    type: string\n",
      "    is_chat_input: false\n",
      "    default: TrailMaster X4 Tent is a durable polyester tent\n",
      "outputs:\n",
      "  phi35_answer:\n",
      "    type: string\n",
      "    reference: ${phi35.output}\n",
      "    is_chat_output: false\n",
      "  gpt4o_answer:\n",
      "    type: string\n",
      "    reference: ${gpt4o.output}\n",
      "    is_chat_output: true\n",
      "nodes:\n",
      "- name: phi35\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: phi35_finetuned.py\n",
      "  inputs:\n",
      "    connection: coneu1-phi3-endpoint-241201\n",
      "    question: ${inputs.question}\n",
      "    context: ${inputs.context}\n",
      "- name: gpt4o\n",
      "  type: llm\n",
      "  source:\n",
      "    type: code\n",
      "    path: chat.jinja2\n",
      "  inputs:\n",
      "    deployment_name: gpt-4o\n",
      "    temperature: 0.7\n",
      "    top_p: 1\n",
      "    max_tokens: 256\n",
      "    question: ${inputs.question}\n",
      "  connection: aoai-tst1\n",
      "  api: chat\n",
      "  module: promptflow.tools.aoai\n",
      "  use_variants: false\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "# Read the template file\n",
    "template = env.get_template('./flow-template/chat-context.flow.dag.yaml')\n",
    "\n",
    "# Define the variables for the template\n",
    "variables = {\n",
    "\t\"your_phi35_connection_name\": \"coneu1-phi3-endpoint-241201\",\n",
    "\t\"your_gpt4o_connection_name\": \"aoai-tst1\"\n",
    "}\n",
    "\n",
    "rendered_content = template.render(variables)\n",
    "Path('./chat-context/flow.dag.yaml').write_text(rendered_content)\n",
    "\n",
    "print(Path('./chat-context/flow.dag.yaml').read_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading questions_outdoor.jsonl\u001b[32m (< 1 MB): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 467/467 [00:00<00:00, 5.70kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading chat-context (0.0 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4785/4785 [00:00<00:00, 14767.55it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-12-15 08:21:14 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-12-15 08:21:14 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_context_variant_0_20241215_082112_494255/details?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/es1u1aif1grp/providers/Microsoft.MachineLearningServices/workspaces/esu1aif1prj\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat-context\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    #context_simple.json中只有固定的一条ctx所以可以这样写\n",
    "}\n",
    "\n",
    "run_result_with_context = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_context_data\",\n",
    "    tags={\"chat_with_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:56<01:52, 56.17s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [01:07<00:29, 29.65s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:18<00:00, 26.19s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4 Tent</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>The TrailMaster X4 Tent is a four-person poly...</td>\n",
       "      <td>The TrailMaster X4 Tent is a spacious, durable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>No, the provided context does not include any...</td>\n",
       "      <td>I'm just a digital assistant, so I don't have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>The TrailMaster X4 Tent is a four-person, dur...</td>\n",
       "      <td>I wish I could sell you a tent, but as an AI a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>I'm an AI and don't have access to current pr...</td>\n",
       "      <td>I can help you with that! While I don't have t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                               tell me about your TrailMaster X4 Tent   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     The TrailMaster X4 Tent is a four-person poly...   \n",
       "1                     No, the provided context does not include any...   \n",
       "2                     The TrailMaster X4 Tent is a four-person, dur...   \n",
       "3                     I'm an AI and don't have access to current pr...   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    The TrailMaster X4 Tent is a spacious, durable...  \n",
       "1                    I'm just a digital assistant, so I don't have ...  \n",
       "2                    I wish I could sell you a tent, but as an AI a...  \n",
       "3                    I can help you with that! While I don't have t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result_with_context)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use serverless endpoint to run the Promptflow with context\n",
    "\n",
    "-   Create a serverless endpoint to run the Promptflow with the context. You can use the endpoint to run the flow with the context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy your serverless endpoint\n",
    "\n",
    "-   go to the Azure AI studio > Model catalog > search phi-3.5 > deply Phi-3.5-mini-instruct as your serverless endpint\n",
    "    <br>\n",
    "    ![serverless endpoint](./images/deploy_serverless_endpoint.jpg)\n",
    "    <br>\n",
    "    <br>\n",
    "-   once the deployment is done, go to Deployments and you can see the endpoint deployed in the endpoint section. Click to check the details and copy key and phi35-mini-instruct: Chat Completion endpoint url\n",
    "    ![copy connection](./images/copy_connection.jpg)\n",
    "    <br>\n",
    "    <br>\n",
    "-   go to Settings in Azure AI studio > Connections > create a new connection naming phi35-serverless with the copied key and endpoint url\n",
    "    ![create new serverless connection](./images/create_new_serverless_connection.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the exist connections\n",
    "\n",
    "-   currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace.\n",
    "    > ✨ **_important_** <br>\n",
    "    > Update flow.dag.yaml files in your flow_path with the connection name you have created in the Azure ML Studio UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
      "environment:\n",
      "  python_requirements_txt: requirements.txt\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "    is_chat_input: true\n",
      "    default: What is the capital of France?\n",
      "  context:\n",
      "    type: string\n",
      "    is_chat_input: false\n",
      "    default: TrailMaster X4 Tent is a durable polyester tent\n",
      "outputs:\n",
      "  phi35_answer:\n",
      "    type: string\n",
      "    reference: ${phi35.output}\n",
      "    is_chat_output: false\n",
      "  gpt4o_answer:\n",
      "    type: string\n",
      "    reference: ${gpt4o.output}\n",
      "    is_chat_output: true\n",
      "nodes:\n",
      "- name: phi35\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: phi35_chatcompletion.py\n",
      "  inputs:\n",
      "    connection: conphi35mini-istru-esu1aif1dpl1\n",
      "    question: ${inputs.question}\n",
      "    context: ${inputs.context}\n",
      "- name: gpt4o\n",
      "  type: llm\n",
      "  source:\n",
      "    type: code\n",
      "    path: chat.jinja2\n",
      "  inputs:\n",
      "    deployment_name: gpt-4o\n",
      "    temperature: 0.2\n",
      "    top_p: 1\n",
      "    max_tokens: 512\n",
      "    question: ${inputs.question}\n",
      "  connection: aoai-tst1\n",
      "  api: chat\n",
      "  module: promptflow.tools.aoai\n",
      "  use_variants: false\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "# Read the template file\n",
    "template = env.get_template('./flow-template/chat-serverless.flow.dag.yaml')\n",
    "\n",
    "# Define the variables for the template with your connection names for chat serverless \n",
    "variables = {\n",
    "\t\"your_phi35_serverless_connection_name\": \"conphi35mini-istru-esu1aif1dpl1\",\n",
    "\t\"your_gpt4o_connection_name\": \"aoai-tst1\"\n",
    "}\n",
    "\n",
    "rendered_content = template.render(variables)\n",
    "Path('./chat-serverless/flow.dag.yaml').write_text(rendered_content)\n",
    "\n",
    "print(Path('./chat-serverless/flow.dag.yaml').read_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chat-serverless (0.0 MBs): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4138/4138 [00:00<00:00, 12642.29it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-12-15 08:22:45 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-12-15 08:22:45 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_serverless_variant_0_20241215_082243_117922/details?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/es1u1aif1grp/providers/Microsoft.MachineLearningServices/workspaces/esu1aif1prj\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat-serverless\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "run_serverless_result = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_serverless_context_data\",\n",
    "    tags={\"chat_serverless_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:55<01:51, 55.83s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [01:07<00:29, 29.73s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:51<00:00, 37.20s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_serverless_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4 Tent</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>The TrailMaster X4 Tent is a robust four-pers...</td>\n",
       "      <td>The TrailMaster X4 Tent is a spacious and dura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm sorry, but I don't have specific climbing...</td>\n",
       "      <td>I don't have any climbing gear myself, but I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>Certainly! The TrailMaster X4 Tent is a robus...</td>\n",
       "      <td>I don't sell tents, but I can help you find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>I'm sorry, but I don't have real-time access ...</td>\n",
       "      <td>I don't have TrekReady Hiking Boots myself, bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                               tell me about your TrailMaster X4 Tent   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     The TrailMaster X4 Tent is a robust four-pers...   \n",
       "1                     I'm sorry, but I don't have specific climbing...   \n",
       "2                     Certainly! The TrailMaster X4 Tent is a robus...   \n",
       "3                     I'm sorry, but I don't have real-time access ...   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    The TrailMaster X4 Tent is a spacious and dura...  \n",
       "1                    I don't have any climbing gear myself, but I c...  \n",
       "2                    I don't sell tents, but I can help you find th...  \n",
       "3                    I don't have TrekReady Hiking Boots myself, bu...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_serverless_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
