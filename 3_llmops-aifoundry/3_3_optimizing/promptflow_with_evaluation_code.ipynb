{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute batch groundness evaluation flow using Promptflow Python SDK\n",
    "\n",
    "### Overview\n",
    "\n",
    "Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality.\n",
    "\n",
    "In this handson, you will be able to:\n",
    "Evaluate your flows, calculate quality and performance metrics with run result datasets.\n",
    "Debug and iterate your flows, especially tracing interaction with LLMs with ease.\n",
    "In order to calculate the other metrics like accuracy, relevance score. Please refer to [Develop evaluation flow](https://microsoft.github.io/promptflow/how-to-guides/develop-a-dag-flow/develop-evaluation-flow.html) to learn how to develop an evaluation flow.\n",
    "\n",
    "#### 1. Create Promptflow client with Credential and configuration\n",
    "\n",
    "#### 2. AI Foundry batch run to get the base run data\n",
    "\n",
    "#### 3. Run Groundedness Evaluation of the Promptflow\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: python31014jvsc74a57bd01f90a0206bde5cf3732dab79adbbcc7570d5fab64b89fc69d46a8fe33664a709\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "lab_prep_dir = os.getcwd().split(\"SLMWorkshopCN\")[0] + \"SLMWorkshopCN/0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(lab_prep_dir))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49aee8bf-3f02-464f-a0ba-e3467e7d85e2\n",
      "rg-slmwrkshp_9\n",
      "slmwrkshp9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import required libraries\n",
    "from promptflow.azure import PFClient\n",
    "from promptflow.entities import Run\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, InteractiveBrowserCredential\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "with open('../3_2_prototyping/config_prd.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(config[\"subscription_id\"])\n",
    "print(config[\"resource_group\"])\n",
    "print(config[\"workspace_name\"]) # Azure AI Foundry project name which is not the same as the Azure ML workspace name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_status(pf_azure_client:PFClient, run_result:Run):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = pf_azure_client.runs.get(run_result).status\n",
    "        if status == \"Preparing\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Completed\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = pf_azure_client.runs.get(run_result).status\n",
    "        pbar.update(1)\n",
    "        print(\"Promptflow Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Promptflow client with Credential and configuration\n",
    "\n",
    "-   Create a promptflow client with the credential and configuration. You need to set the `config_prd.json` file with subscription_id, resource_group and workspace_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ../3_2_prototyping/config_prd.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure AI Foundry Workspace: slmwrkshp9\n",
      "Workspace Location: eastus\n",
      "Workspace ID: /subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourceGroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/slmwrkshp9\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "# if you cannot use DefaultAzureCredential and InteractiveBrowserCredential you need to set up the Managed identity in your .env file\n",
    "\n",
    "pf_azure_client = PFClient.from_config(credential=credential, path=\"../3_2_prototyping/config_prd.json\")\n",
    "\n",
    "try:\n",
    "    workspace = pf_azure_client.ml_client.workspaces.get(name=config[\"workspace_name\"])\n",
    "    print(f\"Connected to Azure AI Foundry Workspace: {workspace.name}\")\n",
    "    print(f\"Workspace Location: {workspace.location}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Failed to connect to Azure ML Workspace: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AI Foundry batch run to get the base run data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the exist connections\n",
    "\n",
    "-   currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace.\n",
    "    > ‚ú® **_important_** <br>\n",
    "    > Update flow.dag.yaml files in your flow_path with the connection name in Azure AI Foundry Management Center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
      "environment:\n",
      "  python_requirements_txt: requirements.txt\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "    is_chat_input: true\n",
      "    default: What is the capital of France?\n",
      "  context:\n",
      "    type: string\n",
      "    is_chat_input: false\n",
      "    default: TrailMaster X4 Tent is a durable polyester tent\n",
      "outputs:\n",
      "  phi35_answer:\n",
      "    type: string\n",
      "    reference: ${phi35.output}\n",
      "    is_chat_output: false\n",
      "  gpt4o_answer:\n",
      "    type: string\n",
      "    reference: ${gpt4o.output}\n",
      "    is_chat_output: true\n",
      "nodes:\n",
      "- name: phi35\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: phi35_chatcompletion.py\n",
      "  inputs:\n",
      "    connection: slmwrkshp_phi35\n",
      "    question: ${inputs.question}\n",
      "    context: ${inputs.context}\n",
      "- name: gpt4o\n",
      "  type: llm\n",
      "  source:\n",
      "    type: code\n",
      "    path: chat.jinja2\n",
      "  inputs:\n",
      "    deployment_name: gpt-4o\n",
      "    temperature: 0.2\n",
      "    top_p: 1\n",
      "    max_tokens: 512\n",
      "    question: ${inputs.question}\n",
      "  connection: cog-pgwgybluulpec\n",
      "  api: chat\n",
      "  module: promptflow.tools.aoai\n",
      "  use_variants: false\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "# Read the template file\n",
    "template = env.get_template('./flow-template/chat-serverless.flow.dag.yaml')\n",
    "\n",
    "# Define the variables for the template with your connection names for chat serverless \n",
    "your_phi35_serverless_connection_name = \"slmwrkshp_phi35\"\n",
    "your_gpt4o_connection_name = \"cog-pgwgybluulpec\"\n",
    "variables = {\n",
    "\t\"your_phi35_serverless_connection_name\": your_phi35_serverless_connection_name,\n",
    "\t\"your_gpt4o_connection_name\": your_gpt4o_connection_name\n",
    "}\n",
    "\n",
    "rendered_content = template.render(variables)\n",
    "Path('../3_2_prototyping/chat-serverless/flow.dag.yaml').write_text(rendered_content)\n",
    "\n",
    "print(Path('../3_2_prototyping/chat-serverless/flow.dag.yaml').read_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
      "environment:\n",
      "  python_requirements_txt: requirements.txt\n",
      "inputs:\n",
      "  question:\n",
      "    type: string\n",
      "    default: What is TrailMaster X4 Tent?\n",
      "  context:\n",
      "    type: string\n",
      "    default:\n",
      "      TrailMaster X4 Tent is a durable polyester tent for four, with water-resistant construction, \n",
      "      multiple doors, interior pockets, and reflective guy lines. Summit Breeze Jacket is lightweight, windproof, \n",
      "      and water-resistant hiking jacket with breathable polyester material, adjustable cuffs, \n",
      "      and secure zippered pockets. TrekReady Hiking Boots is durable leather boots \n",
      "      with reinforced stitching, toe protection, cushioned insoles, and breathable materials for comfort. \n",
      "      BaseCamp Folding Table is lightweight aluminum table, 48 x 24 inches, foldable design. \n",
      "      EcoFire Camping Stove is portable stainless steel stove, lightweight, fuel-efficient, and easy to use.\n",
      "  answer:\n",
      "    type: string\n",
      "    default:\n",
      "      TrailMaster X4 Tent is a durable polyester tent for four, with water-resistant construction, \n",
      "      multiple doors, interior pockets, and reflective guy lines.\n",
      "outputs:\n",
      "  gpt_groundedness:\n",
      "    type: object\n",
      "    reference: ${concat_scores.output.gpt_groundedness}\n",
      "nodes:\n",
      "- name: groundedness_score\n",
      "  type: llm\n",
      "  source:\n",
      "    type: code\n",
      "    path: groundedness_score.jinja2\n",
      "  inputs:\n",
      "    context: ${inputs.context}\n",
      "    answer: ${inputs.answer}\n",
      "    max_tokens: 256\n",
      "    deployment_name: gpt-4o\n",
      "    temperature: 0\n",
      "  connection: cog-pgwgybluulpec\n",
      "  api: chat\n",
      "- name: concat_scores\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: concat_scores.py\n",
      "  inputs:\n",
      "    groundesness_score: ${groundedness_score.output}\n",
      "- name: aggregate_variants_results\n",
      "  type: python\n",
      "  source:\n",
      "    type: code\n",
      "    path: aggregate_variants_results.py\n",
      "  inputs:\n",
      "    results: ${concat_scores.output}\n",
      "  aggregation: true\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "from pathlib import Path\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "# Read the template file\n",
    "template = env.get_template('./flow-template/evaluation.flow.dag.yaml')\n",
    "\n",
    "# Define the variables for the template with your connection names for chat serverless \n",
    "variables = {\n",
    "\t\"your_gpt4o_connection_name\": your_gpt4o_connection_name\n",
    "}\n",
    "\n",
    "rendered_content = template.render(variables)\n",
    "Path('./evaluation/flow.dag.yaml').write_text(rendered_content)\n",
    "\n",
    "print(Path('./evaluation/flow.dag.yaml').read_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chat-serverless (0.0 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4144/4144 [00:01<00:00, 3516.57it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading questions_outdoor.jsonl\u001b[32m (< 1 MB): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 467/467 [00:00<00:00, 1.59kB/s]\n",
      "\u001b[39m\n",
      "\n",
      "[2025-02-20 08:48:25 +0800][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2025-02-20 08:48:25 +0800][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_serverless_variant_0_20250220_084818_827396/details?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/slmwrkshp9\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"../3_2_prototyping/chat-serverless\"\n",
    "data_path = \"../3_2_prototyping/data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('../3_2_prototyping/data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "base_run = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_serverless_context_data\",\n",
    "    tags={\"chat_serverless_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ") # Âú® AI Foundry / Your AI Prj/ Prompt flow/ RunsÊ†áÁ≠æÈ°µ‰∏≠ËÉΩÁúãÂà∞Ëøô‰∏™Ê≠£Âú®Ë∑ëÁöÑpf job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.14s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, base_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4 Tent</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Sure thing! The TrailMaster X4 Tent is a fanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Sure thing! üßó‚Äç‚ôÇÔ∏è\\n\\nYou can find a variety of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>Sure thing! We have a great selection of tents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>Hey there! ü•æ\\n\\nYes, we do have TrekReady Hiki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                               tell me about your TrailMaster X4 Tent   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number outputs.phi35_answer  \\\n",
       "outputs.line_number                                            \n",
       "0                                     0                 None   \n",
       "1                                     1                 None   \n",
       "2                                     2                 None   \n",
       "3                                     3                 None   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    Sure thing! The TrailMaster X4 Tent is a fanta...  \n",
       "1                    Sure thing! üßó‚Äç‚ôÇÔ∏è\\n\\nYou can find a variety of ...  \n",
       "2                    Sure thing! We have a great selection of tents...  \n",
       "3                    Hey there! ü•æ\\n\\nYes, we do have TrekReady Hiki...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(base_run)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Groundedness Evaluation of the Promptflow\n",
    "\n",
    "The eval-groundness flow is illustrating measures how grounded the model's predicted answers are against the context. Even if LLM‚Äôs responses are true, if not verifiable against context, then such responses are considered ungrounded.\n",
    "\n",
    "> üß™ +For Your Information<br> > **Groundedness** is a measure of how well the model's responses are grounded in the context. A grounded response is one that is directly supported by the context. For example, if the context is about a dog, a grounded response would be \"Dogs are mammals.\" An ungrounded response would be \"Dogs can fly.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading evaluation (0.01 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6958/6958 [00:01<00:00, 6671.86it/s] \n",
      "\u001b[39m\n",
      "\n",
      "[2025-02-20 09:22:22 +0800][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2025-02-20 09:22:22 +0800][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/eval_groundedness_02_20_0917/details?wsid=/subscriptions/49aee8bf-3f02-464f-a0ba-e3467e7d85e2/resourcegroups/rg-slmwrkshp_9/providers/Microsoft.MachineLearningServices/workspaces/slmwrkshp9\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "eval_groundedness_flow_path = \"./evaluation/\"\n",
    "data_path = \"./data/qna_outdoor.jsonl\"\n",
    "\n",
    "with open('../3_2_prototyping/data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "        \"context\": context.get(\"context\")    ,\n",
    "        \"answer\": \"${run.outputs.gpt4o_answer}\",#Ê≥®ÊÑè‰∏ãÈù¢runËØ•eval flowÊó∂run=base_run(Âç≥run‰∏äÈù¢ÁöÑÈÇ£‰∏™pfËøîÂõûÁöÑRunÂØπË±°)ÔºåËÄåÊ≠§Â§ÑÈÖçÁΩÆÁöÑÊÑèÊÄùÊòØ‰º†ÂÖ•ÁöÑÈÇ£‰∏™RunÂØπË±°ÁöÑoutputs.gpt4o_answer‰Ωú‰∏∫ËØ•eval flowÁöÑËæìÂÖ•‰∏≠input.answer\n",
    "    }\n",
    "eval_name = \"eval_groundedness\"\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%m_%d_%H%M\")\n",
    "eval_name = str(eval_name + \"_\" + timestamp)\n",
    "\n",
    "eval_groundedness_result = pf_azure_client.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    data=data_path,\n",
    "    run=base_run,  # use run as the variant  #Ê≥®ÊÑèËøô‰∏™base_runÊòØrun‰∏äÈù¢ÁöÑÈÇ£‰∏™pfËøîÂõûÁöÑRunÂØπË±°ÔºåËøôÈáåÊòØÂü∫‰∫éËøô‰∏™RunÂØπË±°ËøõË°åevalÔºåÂè¶Â§ñËøôÈáå‰∏çÂÜçÊúâ‚Äòtype=\"chat\"‚Äô\n",
    "    column_mapping=column_mapping,\n",
    "    display_name=eval_name,\n",
    "    name=eval_name,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# pf_azure_client.stream(eval_groundedness_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.19s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, eval_groundedness_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.gpt_groundedness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>Sure thing! The TrailMaster X4 Tent is a fanta...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you tell me BaseCamp Folding Table?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>Sure thing! üßó‚Äç‚ôÇÔ∏è\\n\\nYou can find a variety of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>Sure thing! We have a great selection of tents...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>Hey there! ü•æ\\n\\nYes, we do have TrekReady Hiki...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                       Can you tell me about your selection of tents?   \n",
       "1                              can you tell me BaseCamp Folding Table?   \n",
       "2                                       Do you have any climbing gear?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                                                         inputs.answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                    Sure thing! The TrailMaster X4 Tent is a fanta...   \n",
       "1                    Sure thing! üßó‚Äç‚ôÇÔ∏è\\n\\nYou can find a variety of ...   \n",
       "2                    Sure thing! We have a great selection of tents...   \n",
       "3                    Hey there! ü•æ\\n\\nYes, we do have TrekReady Hiki...   \n",
       "\n",
       "                     inputs.line_number  outputs.gpt_groundedness  \n",
       "outputs.line_number                                                \n",
       "0                                     0                       3.0  \n",
       "1                                     1                       1.0  \n",
       "2                                     2                       1.0  \n",
       "3                                     3                       1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f2d1801ee30>: Failed to resolve 'westus2-0.in.applicationinsights.azure.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f2d1818be50>: Failed to resolve 'westus2-0.in.applicationinsights.azure.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f2d181889d0>: Failed to resolve 'westus2-0.in.applicationinsights.azure.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f2d18188550>: Failed to resolve 'westus2-0.in.applicationinsights.azure.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f2d18189270>: Failed to resolve 'westus2-0.in.applicationinsights.azure.com' ([Errno -3] Temporary failure in name resolution)\")).\n"
     ]
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(eval_groundedness_result)\n",
    "\n",
    "detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
